{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "65pGDUkl8x95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "NEG = -1e12  # numerical -inf\n",
        "\n",
        "\n",
        "class TSPHypercubeBCJR_SOVA:\n",
        "    \"\"\"\n",
        "    PDF 원래 식 기반으로 다시 정리한 BCJR + SOVA 버전.\n",
        "\n",
        "    - 단일 trellis ψ[t, mask, last]만 사용 (with-β)\n",
        "    - α_t(a)는 항상 ψ_{t-1}에서 직접 계산:\n",
        "        α_t(a) = max_{m_{t-1}, last ∈ m_{t-1}}\n",
        "                    [ ψ_{t-1}(m_{t-1}, last) + s(last, a) ]\n",
        "      (여기에는 β_t는 안 들어가고, 과거 시점 ≤ t-1의 β 정보만 포함)\n",
        "    - trellis → X_{it} 메시지:\n",
        "        ζ_{it}(a) = α_t(a) + β_t(a) - λ_{it}(a)\n",
        "      (∑_{i'≠i} λ_{i't}(a) = β_t(a) - λ_{it}(a) 사용한 형태)\n",
        "    - ψ는 with-β forward trellis:\n",
        "        ψ_t(m_t, a_t) = max_{m_{t-1}, a_{t-1}}\n",
        "            [ ψ_{t-1}(m_{t-1}, a_{t-1}) + s(a_{t-1}, a_t) + β_t(a_t) ]\n",
        "      (코드에서는 t=1..T, β_t(a_t)를 beta[t-1, a_t]에 매핑)\n",
        "    - BCJR backward bwd[t, mask, last]와 함께\n",
        "      Γ_t(m_t,last) = ψ_t(m_t,last) + bwd_t(m_t,last)로 SOVA LLR 계산.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, D, start_city=None,\n",
        "                 damping=0.3, iters=200, verbose=False,\n",
        "                 tiny_tiebreak=False, seed=0,\n",
        "                 patience_no_cost_change=10, cost_tol=1e-12,\n",
        "                 kappa_bcjr=1.0,\n",
        "                 damp_L=0.5, damp_beta=0.5, damp_zeta=0.5):\n",
        "\n",
        "        D = np.array(D, dtype=float)\n",
        "        assert D.shape[0] == D.shape[1], \"D must be square\"\n",
        "        C = D.shape[0]\n",
        "\n",
        "        if start_city is None:\n",
        "            start_city = 0\n",
        "        start_city = int(start_city)\n",
        "        assert 0 <= start_city < C\n",
        "\n",
        "        # permute: start -> last (internal depot)\n",
        "        perm = np.arange(C)\n",
        "        if start_city != C - 1:\n",
        "            perm[start_city], perm[C - 1] = perm[C - 1], perm[start_city]\n",
        "        inv_perm = np.empty(C, dtype=int)\n",
        "        inv_perm[perm] = np.arange(C)\n",
        "\n",
        "        self.orig_D = D\n",
        "        self.D = D[perm][:, perm]\n",
        "        self.perm = perm\n",
        "        self.inv_perm = inv_perm\n",
        "\n",
        "        self.C = C\n",
        "        self.N = C - 1\n",
        "        self.depot = C - 1\n",
        "\n",
        "        self.verbose = verbose\n",
        "        self.damp = float(damping)\n",
        "        self.iters = int(iters)\n",
        "        self.tiny_tiebreak = bool(tiny_tiebreak)\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        self.patience_no_cost_change = int(patience_no_cost_change)\n",
        "        self.cost_tol = float(cost_tol)\n",
        "\n",
        "        # BCJR / SOVA 관련 파라미터\n",
        "        self.kappa_bcjr = float(kappa_bcjr)\n",
        "        self.damp_L = float(damp_L)\n",
        "        self.damp_beta = float(damp_beta)\n",
        "        self.damp_zeta = float(damp_zeta)\n",
        "\n",
        "        # similarity (bigger is better)\n",
        "        mx = np.max(self.D)\n",
        "        self.s = mx - self.D\n",
        "\n",
        "        # trellis 크기\n",
        "        self.T = self.N\n",
        "        self.M = 1 << self.N\n",
        "\n",
        "        # 단일 forward trellis ψ (with-β)\n",
        "        self.psi = np.full((self.T + 1, self.M, self.N), NEG)\n",
        "        self.backptr = np.full((self.T + 1, self.M, self.N, 2), -1, dtype=int)\n",
        "\n",
        "        # backward trellis (with-β, closure 포함)\n",
        "        self.bwd_wb = np.full((self.T + 1, self.M, self.N), NEG)\n",
        "\n",
        "        # α_t(a): ψ_{t-1}로부터 계산\n",
        "        self.alpha = np.full((self.T, self.N), NEG)\n",
        "\n",
        "        # simplified messages\n",
        "        self.gamma_tilde = np.zeros((self.N, self.T))\n",
        "        self.omega_tilde = np.zeros((self.N, self.T))\n",
        "        self.phi_tilde   = np.zeros((self.N, self.T))\n",
        "        self.eta_tilde   = np.zeros((self.N, self.T))\n",
        "        self.rho_tilde   = np.zeros((self.N, self.T))\n",
        "        self.delta_tilde = np.zeros((self.N, self.T))\n",
        "\n",
        "        # λ_t(i,a), ζ_t(i,a), β_t(a)\n",
        "        self.lambda_ = np.zeros((self.T, self.N, self.N))\n",
        "        self.zeta    = np.zeros((self.T, self.N, self.N))\n",
        "        self.beta    = np.zeros((self.T, self.N))\n",
        "\n",
        "        # damping 캐시\n",
        "        self._L_prev    = [np.zeros((self.N, self.N)) for _ in range(self.T)]\n",
        "        self._beta_prev = [np.zeros(self.N)            for _ in range(self.T)]\n",
        "        self._zeta_prev = [np.zeros((self.N, self.N)) for _ in range(self.T)]\n",
        "\n",
        "    # ===================== Public =====================\n",
        "    def run(self):\n",
        "        stable = 0\n",
        "        last_cost = None\n",
        "        best_route, best_cost = None, None\n",
        "\n",
        "        for it in range(self.iters):\n",
        "            # (1) forward trellis & α\n",
        "            self._trellis_forward_and_alpha()\n",
        "\n",
        "            # (2) backward trellis (primal with β + closure)\n",
        "            self._trellis_backward_bcjr()\n",
        "\n",
        "            # (3) BCJR-style SOVA LLR 계산 (T x N)\n",
        "            llr_t = self._compute_sova_llr_from_bcjr()\n",
        "\n",
        "            # (4) 메시지 업데이트\n",
        "            self._update_phi_eta_rho()\n",
        "            self._update_lambda_beta_zeta_delta(\n",
        "                kappa=self.kappa_bcjr,\n",
        "                llr_t=llr_t,\n",
        "                damp_L=self.damp_L,\n",
        "                damp_beta=self.damp_beta,\n",
        "                damp_zeta=self.damp_zeta,\n",
        "            )\n",
        "            self._update_gamma_omega()\n",
        "\n",
        "            if self.tiny_tiebreak:\n",
        "                self.gamma_tilde += 1e-12 * self.rng.standard_normal(self.gamma_tilde.shape)\n",
        "\n",
        "            # (5) route & cost\n",
        "            route = self.estimate_route()\n",
        "            cost = self._route_cost(route)\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"[{it+1:03d}] cost={cost:.12f} route={route}\")\n",
        "\n",
        "            # best primal 추적\n",
        "            if best_cost is None or cost < best_cost:\n",
        "                best_cost, best_route = cost, route\n",
        "\n",
        "            # plateau early stop\n",
        "            if last_cost is not None and abs(cost - last_cost) <= self.cost_tol:\n",
        "                stable += 1\n",
        "            else:\n",
        "                stable = 0\n",
        "            last_cost = cost\n",
        "\n",
        "            if stable >= self.patience_no_cost_change:\n",
        "                return best_route, best_cost\n",
        "\n",
        "        return best_route, best_cost\n",
        "\n",
        "    # ===================== Trellis (single ψ) & α =====================\n",
        "    def _trellis_forward_and_alpha(self):\n",
        "        \"\"\"\n",
        "        ψ_t(m_t, last) : with-β forward metric\n",
        "        α_t(a)         : ψ_{t-1}로부터 계산 (현재 시점 β_t는 포함되지 않음)\n",
        "        \"\"\"\n",
        "        self.psi.fill(NEG)\n",
        "        self.backptr.fill(-1)\n",
        "        self.alpha.fill(NEG)\n",
        "\n",
        "        # t = 1\n",
        "        # α_1(a) = s(depot, a)\n",
        "        # ψ_1(m={a}, a) = s(depot, a) + β_1(a)\n",
        "        for a in range(self.N):\n",
        "            m = 1 << a\n",
        "            gain = self.s[self.depot, a]\n",
        "            self.alpha[0, a] = gain                    # α_1(a)\n",
        "            self.psi[1, m, a] = gain + self.beta[0, a]  # ψ_1\n",
        "            self.backptr[1, m, a] = (0, -1)             # 센티넬\n",
        "\n",
        "        # t = 2..T\n",
        "        full_mask = (1 << self.N) - 1\n",
        "        for t in range(2, self.T + 1):\n",
        "            # 1) α_t(a) 계산: ψ_{t-1}에서 오는 factor→A_t 메시지\n",
        "            #    α_t(a) = max_{m_{t-1},last∈m_{t-1}, a∉m_{t-1}}\n",
        "            #                 [ ψ_{t-1}(m_{t-1},last) + s(last,a) ]\n",
        "            for a in range(self.N):\n",
        "                best_alpha = NEG\n",
        "                for mask in range(self.M):\n",
        "                    if mask == 0 or mask.bit_count() != (t - 1):\n",
        "                        continue\n",
        "                    if mask & (1 << a):\n",
        "                        continue  # 아직 방문 안 한 도시만\n",
        "                    m = mask\n",
        "                    while m:\n",
        "                        last = (m & -m).bit_length() - 1\n",
        "                        m ^= (1 << last)\n",
        "                        cand = self.psi[t - 1, mask, last] + self.s[last, a]\n",
        "                        if cand > best_alpha:\n",
        "                            best_alpha = cand\n",
        "                self.alpha[t - 1, a] = best_alpha\n",
        "\n",
        "            # 2) ψ_t 전이 (with-β)\n",
        "            for mask in range(self.M):\n",
        "                if mask == 0 or mask.bit_count() != (t - 1):\n",
        "                    continue\n",
        "                for a in range(self.N):\n",
        "                    if mask & (1 << a):\n",
        "                        continue\n",
        "                    new_mask = mask | (1 << a)\n",
        "                    best = NEG\n",
        "                    best_last = -1\n",
        "\n",
        "                    m = mask\n",
        "                    while m:\n",
        "                        last = (m & -m).bit_length() - 1\n",
        "                        m ^= (1 << last)\n",
        "                        if last == a:\n",
        "                            continue  # self-loop 금지\n",
        "\n",
        "                        # ψ_{t-1} + s(last,a) + β_t(a)\n",
        "                        cand = self.psi[t - 1, mask, last] + self.s[last, a] + self.beta[t - 1, a]\n",
        "                        if cand > best:\n",
        "                            best = cand\n",
        "                            best_last = last\n",
        "\n",
        "                    if best > self.psi[t, new_mask, a]:\n",
        "                        self.psi[t, new_mask, a] = best\n",
        "                        self.backptr[t, new_mask, a] = (mask, best_last)\n",
        "\n",
        "    # ===================== Backward trellis (BCJR용) =====================\n",
        "    def _trellis_backward_bcjr(self):\n",
        "        \"\"\"\n",
        "        bwd_wb[t, mask, last]:\n",
        "          - t 시점에 (mask,last) 상태에서 시작해서\n",
        "          - 나머지 도시 방문 + depot으로 귀환까지의 최대 future metric.\n",
        "        전이:\n",
        "          - t < T:\n",
        "              bwd[t,mask,last] = max_{a not in mask} { s[last,a] + β_{t+1}(a) + bwd[t+1, mask|{a}, a] }\n",
        "            (코드에선 β_{t+1}(a)를 beta[t, a]로 저장)\n",
        "          - t = T:\n",
        "              full_mask 에 대해서만 closure: s[last, depot]\n",
        "        \"\"\"\n",
        "        self.bwd_wb.fill(NEG)\n",
        "        full_mask = (1 << self.N) - 1\n",
        "\n",
        "        # t = T: full mask에서 depot으로 가는 closure\n",
        "        t = self.T\n",
        "        for last in range(self.N):\n",
        "            mask = full_mask\n",
        "            self.bwd_wb[t, mask, last] = self.s[last, self.depot]\n",
        "\n",
        "        # t = T-1..1 역순\n",
        "        for t in range(self.T - 1, 0, -1):\n",
        "            for mask in range(self.M):\n",
        "                if mask == 0 or mask.bit_count() != t:\n",
        "                    continue\n",
        "                for last in range(self.N):\n",
        "                    if not (mask & (1 << last)):\n",
        "                        continue\n",
        "\n",
        "                    best = NEG\n",
        "                    avail = (~mask) & full_mask\n",
        "                    m = avail\n",
        "                    while m:\n",
        "                        a = (m & -m).bit_length() - 1\n",
        "                        m ^= (1 << a)\n",
        "                        new_mask = mask | (1 << a)\n",
        "                        cand = self.s[last, a] + self.beta[t, a] + self.bwd_wb[t + 1, new_mask, a]\n",
        "                        if cand > best:\n",
        "                            best = cand\n",
        "                    self.bwd_wb[t, mask, last] = best\n",
        "\n",
        "    # ===================== SOVA-style LLR from BCJR =====================\n",
        "    def _compute_sova_llr_from_bcjr(self):\n",
        "        \"\"\"\n",
        "        llr[t, i] ≈\n",
        "          max_{mask, last=i, |mask|=t+1} [ ψ[t+1, mask, i] + bwd[t+1, mask, i] ]\n",
        "          - max_{mask, last≠i, |mask|=t+1} [ ψ[t+1, mask, last] + bwd[t+1, mask, last] ]\n",
        "        여기서 내부 시간 인덱스(t+1)는 1..T 와 매칭, 외부 t는 0..T-1.\n",
        "        \"\"\"\n",
        "        T, N, M = self.T, self.N, self.M\n",
        "        llr = np.zeros((T, N), dtype=float)\n",
        "\n",
        "        for t in range(1, T + 1):  # 내부 시간: 1..T\n",
        "            for i in range(N):\n",
        "                best_with = NEG\n",
        "                best_without = NEG\n",
        "\n",
        "                for mask in range(M):\n",
        "                    if mask == 0 or mask.bit_count() != t:\n",
        "                        continue\n",
        "\n",
        "                    # last = i 인 state\n",
        "                    val_i = self.psi[t, mask, i] + self.bwd_wb[t, mask, i]\n",
        "                    if val_i > best_with:\n",
        "                        best_with = val_i\n",
        "\n",
        "                    # last ≠ i 인 state들 중 최고값\n",
        "                    m2 = mask\n",
        "                    while m2:\n",
        "                        last = (m2 & -m2).bit_length() - 1\n",
        "                        m2 ^= (1 << last)\n",
        "                        if last == i:\n",
        "                            continue\n",
        "                        val = self.psi[t, mask, last] + self.bwd_wb[t, mask, last]\n",
        "                        if val > best_without:\n",
        "                            best_without = val\n",
        "\n",
        "                if best_with <= NEG / 2 and best_without <= NEG / 2:\n",
        "                    llr[t - 1, i] = 0.0\n",
        "                else:\n",
        "                    llr[t - 1, i] = best_with - best_without\n",
        "\n",
        "        return llr\n",
        "\n",
        "    # ===================== Messages =====================\n",
        "    def _update_phi_eta_rho(self):\n",
        "        # φ̃_it = -max_{i'≠i} γ̃_i't\n",
        "        for t in range(self.T):\n",
        "            col = self.gamma_tilde[:, t]\n",
        "            for i in range(self.N):\n",
        "                self.phi_tilde[i, t] = -np.max(np.delete(col, i)) if self.N > 1 else 0.0\n",
        "        # η̃_it = -max_{t'≠t} ω̃_it'\n",
        "        for i in range(self.N):\n",
        "            row = self.omega_tilde[i, :]\n",
        "            for t in range(self.T):\n",
        "                self.eta_tilde[i, t] = -np.max(np.delete(row, t)) if self.T > 1 else 0.0\n",
        "        # ρ̃_it\n",
        "        self.rho_tilde = self.eta_tilde + self.phi_tilde\n",
        "\n",
        "    def _update_lambda_beta_zeta_delta(self, kappa=0.0, llr_t=None,\n",
        "                                       damp_L=0.5, damp_beta=0.5, damp_zeta=0.5):\n",
        "        T, N = self.T, self.N\n",
        "\n",
        "        for t in range(T):\n",
        "            # (1) rhõ -> (rho0, rho1) 복원\n",
        "            r = self.rho_tilde[:, t]  # shape (N,)\n",
        "            rho0 = -r / N             # off-diagonal\n",
        "            rho1 = rho0 + r           # diagonal\n",
        "\n",
        "            # (2) L_new(i,a): a==i→rho1, else→rho0\n",
        "            L_new = np.empty((N, N), float)\n",
        "            for i in range(N):\n",
        "                L_new[i, :] = rho0[i]\n",
        "                L_new[i, i] = rho1[i]\n",
        "\n",
        "            # (3) λ 이중 센터링\n",
        "            L_new -= L_new.mean(axis=1, keepdims=True)\n",
        "            L_new -= L_new.mean(axis=0, keepdims=True)\n",
        "\n",
        "            # (4) λ damping\n",
        "            L_prev = self._L_prev[t]\n",
        "            L = damp_L * L_new + (1 - damp_L) * L_prev\n",
        "            self.lambda_[t] = L\n",
        "\n",
        "            # (5) β_t(a) = sum_i λ_{it}(a)\n",
        "            beta_new = L.sum(axis=0)\n",
        "            beta_new -= beta_new.mean()\n",
        "\n",
        "            # (6) β damping\n",
        "            beta_prev = self._beta_prev[t]\n",
        "            beta_t = damp_beta * beta_new + (1 - damp_beta) * beta_prev\n",
        "            self.beta[t, :] = beta_t\n",
        "\n",
        "            # (7) ζ_it(a) = α_t(a) + β_t(a) - λ_it(a)\n",
        "            a_t = self.alpha[t, :]\n",
        "            Z_new = a_t[np.newaxis, :] + beta_t[np.newaxis, :] - L\n",
        "\n",
        "            # (8) SOVA LLR 주입 (대각 성분)\n",
        "            if kappa and llr_t is not None:\n",
        "                for i in range(N):\n",
        "                    Z_new[i, i] += kappa * llr_t[t, i]\n",
        "\n",
        "            # (9) ζ damping\n",
        "            Z_prev = self._zeta_prev[t]\n",
        "            Z = damp_zeta * Z_new + (1 - damp_zeta) * Z_prev\n",
        "            self.zeta[t] = Z\n",
        "\n",
        "            # (10) δ̃_it = ζ_it(i) - max_{a≠i} ζ_it(a)\n",
        "            for i in range(N):\n",
        "                zi = Z[i, :]\n",
        "                self.delta_tilde[i, t] = 0.0 if N == 1 else (zi[i] - np.max(np.delete(zi, i)))\n",
        "\n",
        "        # 캐시 갱신\n",
        "        self._L_prev    = [self.lambda_[t].copy() for t in range(T)]\n",
        "        self._beta_prev = [self.beta[t].copy()    for t in range(T)]\n",
        "        self._zeta_prev = [self.zeta[t].copy()    for t in range(T)]\n",
        "\n",
        "    def _update_gamma_omega(self):\n",
        "        gamma_new = self.eta_tilde + self.delta_tilde\n",
        "        omega_new = self.phi_tilde + self.delta_tilde\n",
        "        self.gamma_tilde = self.damp * gamma_new + (1 - self.damp) * self.gamma_tilde\n",
        "        self.omega_tilde = self.damp * omega_new + (1 - self.damp) * self.omega_tilde\n",
        "\n",
        "    # ===================== Decode =====================\n",
        "    def estimate_route(self):\n",
        "        full_mask = (1 << self.N) - 1\n",
        "        best_val = NEG\n",
        "        best_last = -1\n",
        "\n",
        "        for last in range(self.N):\n",
        "            base = self.psi[self.T, full_mask, last]\n",
        "            if base <= NEG / 2:\n",
        "                continue\n",
        "            val = base + self.s[last, self.depot]  # closure\n",
        "            if val > best_val:\n",
        "                best_val = val\n",
        "                best_last = last\n",
        "\n",
        "        # backtrack\n",
        "        if best_last < 0:\n",
        "            # fallback: α 기반 greedy\n",
        "            route_internal = [self.depot]\n",
        "            used = set()\n",
        "            for t in range(self.T):\n",
        "                sc = self.alpha[t].copy()\n",
        "                for u in used:\n",
        "                    sc[u] = NEG\n",
        "                if self.tiny_tiebreak:\n",
        "                    sc += 1e-15 * np.arange(self.N)\n",
        "                a = int(np.argmax(sc))\n",
        "                used.add(a)\n",
        "                route_internal.append(a)\n",
        "            route_internal.append(self.depot)\n",
        "        else:\n",
        "            route_inner = []\n",
        "            mask = full_mask\n",
        "            last = best_last\n",
        "            t = self.T\n",
        "            while t > 0 and 0 <= last < self.N:\n",
        "                route_inner.append(last)\n",
        "                prev_mask, prev_last = self.backptr[t, mask, last]\n",
        "                mask, last = prev_mask, prev_last\n",
        "                t -= 1\n",
        "            route_inner.reverse()\n",
        "            route_internal = [self.depot] + route_inner + [self.depot]\n",
        "\n",
        "        return [int(self.inv_perm[c]) for c in route_internal]\n",
        "\n",
        "    def _route_cost(self, route):\n",
        "        return float(sum(self.orig_D[route[k], route[k + 1]] for k in range(len(route) - 1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yh9k3dft2ed7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class TSPBitmask:\n",
        "    def __init__(self, dist, max=50, verbose=False):\n",
        "        self.dist = dist\n",
        "        self.verbose = verbose\n",
        "        self.n = dist.shape[0]\n",
        "        self.dp = {}\n",
        "        self.tour = []\n",
        "        self.min_cost = np.inf\n",
        "        self.max = max\n",
        "\n",
        "    def run(self):\n",
        "        n = self.n\n",
        "        cities = list(range(n - 1))  # exclude depot\n",
        "\n",
        "        dp = {}  # (visited_mask, current_city) → (cost, prev_city)\n",
        "\n",
        "        # Initialize: depot → i\n",
        "        for i in cities:\n",
        "            dp[(1 << i, i)] = (self.dist[n - 1][i], n - 1)\n",
        "\n",
        "        for visited in range(1 << (n - 1)):\n",
        "            for u in cities:\n",
        "                if not (visited & (1 << u)):\n",
        "                    continue\n",
        "                for v in cities:\n",
        "                    if visited & (1 << v):\n",
        "                        continue\n",
        "                    if self.dist[u][v] >= self.max:\n",
        "                        continue\n",
        "                    new_visited = visited | (1 << v)\n",
        "                    prev_cost = dp.get((visited, u), (np.inf, -1))[0]\n",
        "                    new_cost = prev_cost + self.dist[u][v]\n",
        "                    if (new_visited, v) not in dp or new_cost < dp[(new_visited, v)][0]:\n",
        "                        dp[(new_visited, v)] = (new_cost, u)\n",
        "\n",
        "        end_mask = (1 << (n - 1)) - 1\n",
        "        min_cost = np.inf\n",
        "        last_city = -1\n",
        "        for u in cities:\n",
        "            cost_to_depot = dp.get((end_mask, u), (np.inf, -1))[0] + self.dist[u][n - 1]\n",
        "            if cost_to_depot < min_cost:\n",
        "                min_cost = cost_to_depot\n",
        "                last_city = u\n",
        "\n",
        "        # Reconstruct path\n",
        "        tour = [n - 1]  # start from depot\n",
        "        mask = end_mask\n",
        "        curr = last_city\n",
        "        for _ in range(n - 1):\n",
        "            tour.append(curr)\n",
        "            mask, curr = mask ^ (1 << curr), dp[(mask, curr)][1]\n",
        "        tour.append(n - 1)\n",
        "        tour.reverse()\n",
        "\n",
        "        self.dp = dp\n",
        "        self.tour = tour\n",
        "        self.min_cost = min_cost\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Tour (1-based): {[x+1 for x in tour]}\")\n",
        "            print(f\"Total Cost: {min_cost:.4f}\")\n",
        "\n",
        "        return tour, min_cost\n",
        "\n",
        "    def get_path(self):\n",
        "        return self.tour\n",
        "\n",
        "    def get_cost(self):\n",
        "        return self.min_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "duNo4NCE2iHR",
        "outputId": "475e1f99-0449-4632-df97-cf5c7ea3aa1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13, 0, 11, 5, 4, 3, 8, 7, 2, 6, 9, 1, 10, 12, 13] 1.5541694438785765 0.4873008728027344\n",
            "[13, 0, 11, 5, 4, 3, 8, 7, 2, 6, 9, 1, 10, 12, 13] 1.5541694438785765 8.418556213378906\n",
            "[13, 0, 11, 5, 4, 3, 8, 7, 2, 6, 9, 1, 10, 12, 13] 1.5541694438785765 18.299875736236572\n"
          ]
        }
      ],
      "source": [
        "N = 14\n",
        "d = np.random.rand(N,N)\n",
        "import time\n",
        "\n",
        "start_time1 = time.time()\n",
        "solver_1 = TSPBitmask(d, verbose=False)\n",
        "path1, cost1 = solver_1.run()\n",
        "end_time1 = time.time()\n",
        "print(path1, cost1, end_time1-start_time1)\n",
        "\n",
        "start_time2 = time.time()\n",
        "solver_2 = TSPHypercubeSimplified_PatchA(d, iters=200, start_city=N-1, verbose=False)\n",
        "path2, cost2 = solver_2.run()\n",
        "end_time2 = time.time()\n",
        "print(path2, cost2, end_time2-start_time2)\n",
        "\n",
        "start_time3 = time.time()\n",
        "solver_3 = TSPHypercubeBCJR_SOVA(d, iters=200, start_city=N-1, verbose=False)\n",
        "path3, cost3 = solver_3.run()\n",
        "end_time3 = time.time()\n",
        "print(path3, cost3, end_time3-start_time3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0.   1134.71  779.76 1132.89  922.69  519.3   309.69 1052.6   938.16\n",
            "   621.82  522.1   858.36 1167.38 1046.9 ]\n",
            " [1134.71    0.    387.76  167.2   292.03  724.17 1034.7   342.79  579.22\n",
            "   923.35 1222.99  822.1   670.88  830.54]\n",
            " [ 779.76  387.76    0.    353.55  145.23  336.49  648.36  300.67  350.96\n",
            "   554.48  838.14  520.69  558.49  605.6 ]\n",
            " [1132.89  167.2   353.55    0.    216.08  670.69  988.92  190.26  441.56\n",
            "   830.81 1148.33  694.35  506.66  679.82]\n",
            " [ 922.69  292.03  145.23  216.08    0.    455.21  773.18  168.63  313.21\n",
            "   632.89  940.56  538.01  474.43  576.18]\n",
            " [ 519.3   724.17  336.49  670.69  455.21    0.    318.4   552.73  419.45\n",
            "   271.86  505.6   394.65  651.71  564.9 ]\n",
            " [ 309.69 1034.7   648.36  988.92  773.18  318.4     0.    866.83  698.87\n",
            "   319.92  267.44  570.35  911.44  760.89]\n",
            " [1052.6   342.79  300.67  190.26  168.63  552.73  866.83    0.    254.01\n",
            "   668.92  996.61  509.26  335.17  490.35]\n",
            " [ 938.16  579.22  350.96  441.56  313.21  419.45  698.87  254.01    0.\n",
            "   446.16  780.16  255.89  236.69  263.47]\n",
            " [ 621.82  923.35  554.48  830.81  632.89  271.86  319.92  668.92  446.16\n",
            "     0.    334.02  258.59  624.47  447.15]\n",
            " [ 522.1  1222.99  838.14 1148.33  940.56  505.6   267.44  996.61  780.16\n",
            "   334.02    0.    574.25  949.92  748.83]\n",
            " [ 858.36  822.1   520.69  694.35  538.01  394.65  570.35  509.26  255.89\n",
            "   258.59  574.25    0.    376.58  190.54]\n",
            " [1167.38  670.88  558.49  506.66  474.43  651.71  911.44  335.17  236.69\n",
            "   624.47  949.92  376.58    0.    238.44]\n",
            " [1046.9   830.54  605.6   679.82  576.18  564.9   760.89  490.35  263.47\n",
            "   447.15  748.83  190.54  238.44    0.  ]]\n",
            "[0, 6, 10, 9, 11, 13, 12, 8, 7, 3, 1, 4, 2, 5, 0] 3739.917257835966\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "'''\n",
        "cities = [\n",
        "    \"Seoul\", \"Busan\", \"Daegu\", \"Daejeon\", \"Gwangju\", \n",
        "    \"Incheon\", \"Suwon\", \"Gangneung\", \"Mokpo\", \"Yeosu\",\n",
        "    \"Cheonan\", \"Wonju\", \"Dangjin\"\n",
        "]\n",
        "# 각 도시의 (경도, 위도)\n",
        "coords = np.array([\n",
        "    [126.9780, 37.5665],  # 서울\n",
        "    [129.0756, 35.1796],  # 부산\n",
        "    [128.6014, 35.8714],  # 대구\n",
        "    [127.3850, 36.3510],  # 대전\n",
        "    [126.8514, 35.1600],  # 광주\n",
        "    [126.7052, 37.4563],  # 인천\n",
        "    [127.0182, 37.2636],  # 수원\n",
        "    [128.8961, 37.7519],  # 강릉\n",
        "    [126.3922, 34.8118],  # 목포\n",
        "    [127.6622, 34.7604],  # 여수\n",
        "    [127.1522, 36.8151],  # 천안\n",
        "    [127.9453, 37.3422],  # 원주\n",
        "    [126.6290, 36.8943],  # 당진\n",
        "])'''\n",
        "\n",
        "coords = np.array([\n",
        "    (94.0, 824.0),\n",
        "    (1228.0, 784.0),\n",
        "    (858.0, 668.0),\n",
        "    (1208.0, 618.0),\n",
        "    (992.0, 612.0),\n",
        "    (540.0, 558.0),\n",
        "    (222.0, 542.0),\n",
        "    (1086.0, 472.0),\n",
        "    (884.0, 318.0),\n",
        "    (438.0, 306.0),\n",
        "    (104.0, 302.0),\n",
        "    (666.0, 184.0),\n",
        "    (1040.0, 140.0),\n",
        "    (814.0, 64.0)\n",
        "], dtype=float)\n",
        "# 번호는 1~14로 부여\n",
        "indices = np.arange(1, 15)\n",
        "N = len(coords)\n",
        "dist = np.zeros((N, N))\n",
        "for i in range(N):\n",
        "    for j in range(N):\n",
        "        dist[i, j] = np.linalg.norm(coords[i] - coords[j])\n",
        "np.set_printoptions(precision=2, suppress=True)\n",
        "#print(dist)\n",
        "\n",
        "solver = TSPHypercubeBCJR_SOVA(dist, verbose=False)\n",
        "path4, cost4 = solver.run()\n",
        "print(path4, cost4)\n",
        "\n",
        "def plot_cities_and_path(coords, cities, path):\n",
        "    fig, ax = plt.subplots(figsize=(8, 10))\n",
        "\n",
        "    x = coords[:, 0]\n",
        "    y = coords[:, 1]\n",
        "\n",
        "    # 도시 점 찍기\n",
        "    ax.scatter(x, y, c='black', s=50)\n",
        "\n",
        "    # 도시 이름 표시\n",
        "    for i, name in enumerate(cities):\n",
        "        ax.text(x[i] + 0.03, y[i] + 0.03, name, fontsize=10)\n",
        "\n",
        "    # path 이동 경로 빨간 선으로\n",
        "    for i in range(len(path) - 1):\n",
        "        a = path[i]\n",
        "        b = path[i + 1]\n",
        "        ax.plot([x[a], x[b]], [y[a], y[b]], 'r-', linewidth=2)\n",
        "\n",
        "    # 시작점 강조\n",
        "    ax.scatter(x[path[0]], y[path[0]], c='red', s=100, label=\"Start\")\n",
        "\n",
        "    ax.set_title(\"Relative 2D Projection\")\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# 실행\n",
        "plot_cities_and_path(coords, indices, path4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-jctbL9-aPL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Iter 0] New Best Cost: 57.3547 (Valid Path)\n",
            "[Iter 1] Cost: 61.5082\n",
            "[Iter 2] New Best Cost: 56.6872 (Valid Path)\n",
            "[Iter 3] New Best Cost: 42.3037 (Valid Path)\n",
            "[Iter 4] Cost: 45.7615\n",
            "[Iter 5] New Best Cost: 35.3867 (Valid Path)\n",
            "[Iter 6] New Best Cost: 34.4768 (Valid Path)\n",
            "[Iter 7] New Best Cost: 34.4768 (Valid Path)\n",
            "[Iter 8] Cost: 34.4768\n",
            "[Iter 9] Cost: 34.4768\n",
            "[Iter 10] Cost: 34.4768\n",
            "[Iter 11] Cost: 34.4768\n",
            "[Iter 12] Cost: 34.4768\n",
            "[Iter 13] Cost: 34.4768\n",
            "[Iter 14] Cost: 34.4768\n",
            "[Iter 15] Cost: 34.4768\n",
            "[Iter 16] Cost: 34.4768\n",
            "[Iter 17] Cost: 34.4768\n",
            "[Iter 18] Cost: 34.4768\n",
            "[Iter 19] Cost: 34.4768\n",
            "[Iter 20] Cost: 34.4768\n",
            "[Iter 21] Cost: 34.4768\n",
            "[Iter 22] Cost: 34.4768\n",
            "[Iter 23] Cost: 34.4768\n",
            "[Iter 24] Cost: 34.4768\n",
            "[Iter 25] Cost: 34.4768\n",
            "[Iter 26] Cost: 34.4768\n",
            "[Iter 27] Cost: 34.4768\n",
            "[Iter 28] Cost: 34.4768\n",
            "[Iter 29] Cost: 34.4768\n",
            "[Iter 30] Cost: 34.4768\n",
            "[Iter 31] Cost: 34.4768\n",
            "[Iter 32] Cost: 34.4768\n",
            "[Iter 33] Cost: 34.4768\n",
            "[Iter 34] Cost: 34.4768\n",
            "[Iter 35] Cost: 34.4768\n",
            "[Iter 36] Cost: 34.4768\n",
            "[Iter 37] Cost: 34.4768\n",
            "[Iter 38] Cost: 34.4768\n",
            "[Iter 39] Cost: 34.4768\n",
            "[Iter 40] Cost: 34.4768\n",
            "[Iter 41] Cost: 34.4768\n",
            "[Iter 42] Cost: 34.4768\n",
            "[Iter 43] Cost: 34.4768\n",
            "[Iter 44] Cost: 34.4768\n",
            "[Iter 45] Cost: 34.4768\n",
            "[Iter 46] Cost: 34.4768\n",
            "[Iter 47] Cost: 34.4768\n",
            "[Iter 48] Cost: 34.4768\n",
            "[Iter 49] Cost: 34.4768\n",
            "[Iter 50] Cost: 34.4768\n",
            "[Iter 51] Cost: 34.4768\n",
            "[Iter 52] Cost: 34.4768\n",
            "[Iter 53] Cost: 34.4768\n",
            "[Iter 54] Cost: 34.4768\n",
            "[Iter 55] Cost: 34.4768\n",
            "[Iter 56] Cost: 34.4768\n",
            "[Iter 57] Cost: 34.4768\n",
            "[Iter 58] Cost: 34.4768\n",
            "[Iter 59] Cost: 34.4768\n",
            "[Iter 60] Cost: 34.4768\n",
            "[Iter 61] Cost: 34.4768\n",
            "[Iter 62] Cost: 34.4768\n",
            "[Iter 63] Cost: 34.4768\n",
            "[Iter 64] Cost: 34.4768\n",
            "[Iter 65] Cost: 34.4768\n",
            "[Iter 66] Cost: 34.4768\n",
            "[Iter 67] Cost: 34.4768\n",
            "[Iter 68] Cost: 34.4768\n",
            "[Iter 69] Cost: 34.4768\n",
            "[Iter 70] Cost: 34.4768\n",
            "[Iter 71] Cost: 34.4768\n",
            "[Iter 72] Cost: 34.4768\n",
            "[Iter 73] Cost: 34.4768\n",
            "[Iter 74] Cost: 34.4768\n",
            "[Iter 75] Cost: 34.4768\n",
            "[Iter 76] Cost: 34.4768\n",
            "[Iter 77] Cost: 34.4768\n",
            "[Iter 78] Cost: 34.4768\n",
            "[Iter 79] Cost: 34.4768\n",
            "[Iter 80] Cost: 34.4768\n",
            "[Iter 81] Cost: 34.4768\n",
            "[Iter 82] Cost: 34.4768\n",
            "[Iter 83] Cost: 34.4768\n",
            "[Iter 84] Cost: 34.4768\n",
            "[Iter 85] Cost: 34.4768\n",
            "[Iter 86] Cost: 34.4768\n",
            "[Iter 87] Cost: 34.4768\n",
            "[Iter 88] Cost: 34.4768\n",
            "[Iter 89] Cost: 34.4768\n",
            "[Iter 90] Cost: 34.4768\n",
            "[Iter 91] Cost: 34.4768\n",
            "[Iter 92] Cost: 34.4768\n",
            "[Iter 93] Cost: 34.4768\n",
            "[Iter 94] Cost: 34.4768\n",
            "[Iter 95] Cost: 34.4768\n",
            "[Iter 96] Cost: 34.4768\n",
            "[Iter 97] Cost: 34.4768\n",
            "[Iter 98] Cost: 34.4768\n",
            "[Iter 99] Cost: 34.4768\n",
            "\n",
            "Final Solution Path: [0, 6, 1, 7, 5, 9, 8, 2, 4, 3]\n",
            "Final Cost: 34.47683670397288\n",
            "\n",
            "Bitmask Solution Path: [9, 8, 3, 4, 2, 0, 1, 6, 7, 5, 9]\n",
            "Bitmask Cost: 29.89220324449447\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "####### Relaxation method, 의외로 잘 되는듯, 속도는 빠른데 최적은 어림도 없음########\n",
        "class TSP_PDF_Solver:\n",
        "    def __init__(self, dist_matrix, damping=0.5, verbose=True):\n",
        "        \"\"\"\n",
        "        :param dist_matrix: N x N 거리 행렬\n",
        "        :param damping: Lambda 업데이트 시 진동을 막기 위한 Damping factor (0 < damping <= 1)\n",
        "        :param verbose: 디버그 출력 여부\n",
        "        \"\"\"\n",
        "        self.dist = dist_matrix\n",
        "        self.N = dist_matrix.shape[0]\n",
        "        self.damping = damping\n",
        "        self.verbose = verbose\n",
        "        \n",
        "        # PDF Eq 모델에 따른 변수 초기화\n",
        "        # lambda_t(i): Time t에 City i를 방문하는 것에 대한 Lagrange Multiplier\n",
        "        self.lam = np.zeros((self.N, self.N)) \n",
        "\n",
        "    def solve(self, max_iter=100):\n",
        "        best_path = None\n",
        "        best_cost = float('inf')\n",
        "\n",
        "        for it in range(max_iter):\n",
        "            # 1. Trellis 구성 (Alpha, Beta 계산)\n",
        "            # G_t(x_{t-1}, x_t) + lambda_t(x_t) 형태의 에너지를 기반으로 함\n",
        "            alpha = self._run_forward_alpha()\n",
        "            beta = self._run_backward_beta()\n",
        "\n",
        "            # 2. Soft Output (LLR) delta_tilde 계산 [Fix 2 & 3 반영]\n",
        "            # PDF Eq (3.6)에 따라 순수 Posterior Ratio 계산\n",
        "            delta_tilde = self._compute_soft_output(alpha, beta)\n",
        "\n",
        "            # 3. 최적 경로 추출 (MAP 추정)\n",
        "            current_path, current_cost = self._decode_path(delta_tilde)\n",
        "\n",
        "            # 4. 결과 모니터링\n",
        "            if current_cost < best_cost:\n",
        "                best_cost = current_cost\n",
        "                best_path = current_path\n",
        "                if self.verbose:\n",
        "                    print(f\"[Iter {it}] New Best Cost: {best_cost:.4f} (Valid Path)\")\n",
        "            else:\n",
        "                if self.verbose:\n",
        "                    print(f\"[Iter {it}] Cost: {current_cost:.4f}\")\n",
        "\n",
        "            # 5. Lambda 업데이트 [Fix 1 반영]\n",
        "            # PDF Eq (1.2): 대각 성분은 빼고, 비대각 성분은 더함\n",
        "            update_term = self._compute_lambda_update(delta_tilde)\n",
        "            \n",
        "            # Damping 적용하여 업데이트\n",
        "            self.lam = self.lam + self.damping * update_term\n",
        "\n",
        "        return best_path, best_cost\n",
        "\n",
        "    def _get_edge_weight(self, t, u, v):\n",
        "        \"\"\"\n",
        "        Trellis 간선 가중치 계산\n",
        "        W_t(u, v) = -Distance(u, v) + Lambda_t(v)\n",
        "        * PDF 모델에서는 에너지를 최대화(Max-Sum)하는 관점이므로 거리에 마이너스 부호\n",
        "        \"\"\"\n",
        "        # t 시점에서 u -> v 로 갈 때의 가중치\n",
        "        # lambda는 '도착 노드 v'가 시간 t에 할당되는 제약 조건과 관련됨 (혹은 t+1, 구현에 따라 정의)\n",
        "        # 여기서는 Time t (도착시간)에 City v를 방문하는 비용으로 정의\n",
        "        return -self.dist[u, v] + self.lam[t, v]\n",
        "\n",
        "    def _run_forward_alpha(self):\n",
        "        \"\"\"\n",
        "        Forward Pass (Alpha)\n",
        "        alpha[t, v] = max_u ( alpha[t-1, u] + Weight(u, v) )\n",
        "        \"\"\"\n",
        "        alpha = np.full((self.N, self.N), -np.inf)\n",
        "        \n",
        "        # t=0 초기화 (첫 도시는 0번 도시로 고정 가정, 혹은 Start Node 처리)\n",
        "        # 일반적으로 TSP는 0번 노드에서 시작한다고 가정\n",
        "        alpha[0, 0] = 0 \n",
        "        \n",
        "        for t in range(1, self.N):\n",
        "            for v in range(self.N): # 현재 노드 (t)\n",
        "                scores = []\n",
        "                for u in range(self.N): # 이전 노드 (t-1)\n",
        "                    if alpha[t-1, u] == -np.inf: continue\n",
        "                    # 가중치: u -> v 로 이동하며 t 시점에 v에 도착\n",
        "                    weight = self._get_edge_weight(t, u, v)\n",
        "                    scores.append(alpha[t-1, u] + weight)\n",
        "                \n",
        "                if scores:\n",
        "                    alpha[t, v] = np.max(scores)\n",
        "        \n",
        "        return alpha\n",
        "\n",
        "    def _run_backward_beta(self):\n",
        "        \"\"\"\n",
        "        Backward Pass (Beta) [Fix 3: Backward Definition Strictness]\n",
        "        PDF Eq: beta_t(u) = max_v ( G_{t+1}(u, v) + beta_{t+1}(v) )\n",
        "        * 중요: beta는 '현재 상태 u'에서 '미래의 최대 이득'을 담음.\n",
        "        * t 시점의 lambda는 이미 Alpha 혹은 Edge Weight에 포함되므로 중복 사용 주의.\n",
        "        \"\"\"\n",
        "        beta = np.full((self.N, self.N), -np.inf)\n",
        "        \n",
        "        # 마지막 단계 (Return to Start) 처리\n",
        "        # t=N-1 (마지막 도시) -> t=N (다시 0번 도시)\n",
        "        for u in range(self.N):\n",
        "            # 마지막에서 시작점으로 돌아오는 비용 (Cyclic TSP)\n",
        "            # 여기서는 t=0 의 lambda를 다시 더하지 않음 (보통 Loop Closing은 거리만 고려)\n",
        "            beta[self.N-1, u] = -self.dist[u, 0] \n",
        "\n",
        "        # t = N-2 부터 0 까지 역방향 진행\n",
        "        for t in range(self.N - 2, -1, -1):\n",
        "            for u in range(self.N): # 현재 노드 (t)\n",
        "                scores = []\n",
        "                for v in range(self.N): # 다음 노드 (t+1)\n",
        "                    # 다음 노드 v로 가는 가중치 (t+1 시점의 lambda 포함)\n",
        "                    weight = self._get_edge_weight(t+1, u, v)\n",
        "                    \n",
        "                    if beta[t+1, v] != -np.inf:\n",
        "                        scores.append(weight + beta[t+1, v])\n",
        "                \n",
        "                if scores:\n",
        "                    beta[t, u] = np.max(scores)\n",
        "                    \n",
        "        return beta\n",
        "\n",
        "    def _compute_soft_output(self, alpha, beta):\n",
        "        \"\"\"\n",
        "        [Fix 2] Soft Output (LLR) delta_tilde 계산\n",
        "        PDF Eq (3.6): delta(i) = Max(x in X_i) - Max(x not in X_i)\n",
        "        * 임의로 lambda를 빼거나 더하지 않음.\n",
        "        * 오직 Trellis Score (Alpha + Beta) 만을 사용.\n",
        "        \"\"\"\n",
        "        delta_tilde = np.zeros((self.N, self.N))\n",
        "        \n",
        "        # Total Score Matrix: S[t, i] = alpha[t, i] + beta[t, i]\n",
        "        # 이 값은 (t, i)를 반드시 지나는 경로 중 최대 Score를 의미함\n",
        "        total_scores = alpha + beta\n",
        "        \n",
        "        for t in range(self.N):\n",
        "            # t 시점의 모든 노드에 대한 Score\n",
        "            row_scores = total_scores[t, :]\n",
        "            \n",
        "            # Global Max at time t (해당 시점에서 가장 유력한 경로의 점수)\n",
        "            # 주의: Max(x not in X_i)를 구하기 위해, i를 제외한 나머지 중 Max를 찾아야 함\n",
        "            \n",
        "            # 효율적인 계산을 위해 미리 정렬하거나 마스킹 사용\n",
        "            for i in range(self.N):\n",
        "                score_in = row_scores[i]\n",
        "                \n",
        "                # i를 제외한 나머지 노드들의 점수 중 최대값\n",
        "                # mask를 씌워서 max 계산\n",
        "                other_scores = np.delete(row_scores, i)\n",
        "                score_out = np.max(other_scores) if len(other_scores) > 0 else -np.inf\n",
        "                \n",
        "                # Eq 3.6 정의 준수\n",
        "                delta_tilde[t, i] = score_in - score_out\n",
        "                \n",
        "        return delta_tilde\n",
        "\n",
        "    def _compute_lambda_update(self, delta_tilde):\n",
        "        \"\"\"\n",
        "        [Fix 1] Lambda Bias Update\n",
        "        PDF Eq (1.2): lambda_t(i) 업데이트 텀 계산\n",
        "        Formula: -rho(i, i) + sum_{j != i} rho(i, j)\n",
        "        여기서 rho는 delta_tilde (Soft Output)를 의미\n",
        "        \"\"\"\n",
        "        update_matrix = np.zeros_like(delta_tilde)\n",
        "        \n",
        "        for t in range(self.N):\n",
        "            # t 시점의 delta_tilde 벡터\n",
        "            rho_vec = delta_tilde[t, :]\n",
        "            \n",
        "            sum_rho = np.sum(rho_vec) # sum_{all j} rho(i, j)\n",
        "            \n",
        "            for i in range(self.N):\n",
        "                # sum_{j != i} rho = (Total Sum) - rho(i)\n",
        "                sum_others = sum_rho - rho_vec[i]\n",
        "                \n",
        "                # 식 적용: -rho(i) + sum_others\n",
        "                update_matrix[t, i] = -rho_vec[i] + sum_others\n",
        "                \n",
        "        return update_matrix\n",
        "\n",
        "    def _decode_path(self, delta_tilde):\n",
        "        \"\"\"\n",
        "        delta_tilde 값을 기반으로 가장 유력한 경로를 Greedy하게 선택하거나\n",
        "        단순히 Argmax를 취함 (여기서는 LLR이 가장 큰 순서대로 선택하되 방문 제약 고려)\n",
        "        \"\"\"\n",
        "        path = [-1] * self.N\n",
        "        visited = [False] * self.N\n",
        "        \n",
        "        # 간단한 Greedy Decoding: 각 시간 t마다 LLR이 가장 큰 도시 선택 (충돌 회피)\n",
        "        # 실제로는 Trellis Backtracking이 더 정확하지만, Iteration 모니터링 용도\n",
        "        \n",
        "        # 0번 도시는 0번 타임 고정\n",
        "        path[0] = 0\n",
        "        visited[0] = True\n",
        "        \n",
        "        cost = 0\n",
        "        \n",
        "        for t in range(1, self.N):\n",
        "            best_node = -1\n",
        "            best_val = -np.inf\n",
        "            \n",
        "            for i in range(self.N):\n",
        "                if not visited[i]:\n",
        "                    if delta_tilde[t, i] > best_val:\n",
        "                        best_val = delta_tilde[t, i]\n",
        "                        best_node = i\n",
        "            \n",
        "            if best_node != -1:\n",
        "                path[t] = best_node\n",
        "                visited[best_node] = True\n",
        "                cost += self.dist[path[t-1], path[t]]\n",
        "        \n",
        "        # Return to start cost\n",
        "        if -1 not in path:\n",
        "            cost += self.dist[path[-1], path[0]]\n",
        "            return path, cost\n",
        "        else:\n",
        "            return path, float('inf')\n",
        "\n",
        "# --- 실행 예시 ---\n",
        "if __name__ == \"__main__\":\n",
        "    # 간단한 5도시 예제 (대칭)\n",
        "    N = 10\n",
        "    coords = np.random.rand(N, 2) * 10\n",
        "    dist_matrix = np.zeros((N, N))\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            dist_matrix[i, j] = np.linalg.norm(coords[i] - coords[j])\n",
        "\n",
        "    # Solver 실행\n",
        "    solver = TSP_PDF_Solver(dist_matrix, damping=0.5, verbose=True)\n",
        "    best_path, best_cost = solver.solve(max_iter=100)\n",
        "    \n",
        "    print(\"\\nFinal Solution Path:\", best_path)\n",
        "    print(\"Final Cost:\", best_cost)\n",
        "    \n",
        "    solver2 = TSPBitmask(dist_matrix)\n",
        "    path2, cost2 = solver2.run()\n",
        "    print(\"\\nBitmask Solution Path:\", path2)\n",
        "    print(\"Bitmask Cost:\", cost2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Solving with LLR Feedback (Constraint Scale=0.04, LLR Strength=0.5)\n",
            "[Iter 0] Cost: 209.43 (New Best!) | Lock-in Activated\n",
            "[Iter 1] Cost: 209.43\n",
            "[Iter 2] Cost: 209.43\n",
            "[Iter 3] Cost: 209.43\n",
            "[Iter 4] Cost: 209.43\n",
            "[Iter 5] Cost: 209.43\n",
            "[Iter 6] Cost: 209.43\n",
            "[Iter 7] Cost: 209.43\n",
            "[Iter 8] Cost: 209.43\n",
            "[Iter 9] Cost: 209.43\n",
            "[Iter 10] Cost: 209.43\n",
            "[Iter 11] Cost: 209.43\n",
            "[Iter 12] Cost: 209.43\n",
            "[Iter 13] Cost: 209.43\n",
            "[Iter 14] Cost: 209.43\n",
            "[Iter 15] Cost: 209.43\n",
            "[Iter 16] Cost: 209.43\n",
            "[Iter 17] Cost: 209.43\n",
            "[Iter 18] Cost: 209.43\n",
            "[Iter 19] Cost: 209.43\n",
            "\n",
            "Final Result: [13, 12, 8, 5, 9, 10, 3, 4, 1, 0, 11, 7, 6, 2, 13], Cost: 209.42776189036024\n",
            "\n",
            "Bitmask Result: [13, 12, 8, 5, 9, 10, 3, 4, 1, 0, 11, 7, 6, 2, 13], Cost: 209.42776189036024\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "INF = 1e12 \n",
        "#####진짜 제일 잘되는 애는 얘######### LLR 이중으로 들어감\n",
        "class TSPSolverLLRFeedback:\n",
        "    def __init__(self, dist_matrix, bp_iterations=50, damping=0.7, \n",
        "                 scaling_factor=0.01, feedback_strength=0.5, verbose=True):\n",
        "        \"\"\"\n",
        "        scaling_factor (0.01): 제약 조건(Lambda)을 얼마나 반영할지 (작을수록 간섭 줄임)\n",
        "        feedback_strength (0.5): LLR(자기확신)을 얼마나 반영할지 (클수록 한번 찾은 길 고정)\n",
        "        \"\"\"\n",
        "        self.dist_matrix = np.array(dist_matrix)\n",
        "        self.num_nodes = self.dist_matrix.shape[0]\n",
        "        self.N = self.num_nodes - 1\n",
        "        self.depot = self.N\n",
        "        self.bp_iterations = bp_iterations\n",
        "        self.damping = damping\n",
        "        self.verbose = verbose\n",
        "        \n",
        "        # 파라미터 저장\n",
        "        self.scaling_factor = scaling_factor\n",
        "        self.feedback_strength = feedback_strength\n",
        "        \n",
        "        # S 행렬 (대각성분 제거)\n",
        "        max_dist = np.max(self.dist_matrix)\n",
        "        self.S = max_dist - self.dist_matrix\n",
        "        np.fill_diagonal(self.S, -INF) \n",
        "        \n",
        "        # Messages\n",
        "        self.tilde_rho = np.zeros((self.N, self.N))\n",
        "        self.tilde_eta = np.zeros((self.N, self.N))\n",
        "        self.tilde_phi = np.zeros((self.N, self.N))\n",
        "        \n",
        "        # [핵심] 이전 이터레이션의 LLR(tilde_delta) 저장용\n",
        "        self.last_llr = np.zeros((self.N, self.N))\n",
        "\n",
        "    def log(self, msg):\n",
        "        if self.verbose:\n",
        "            print(msg)\n",
        "\n",
        "    def _calc_total_bias(self):\n",
        "        \"\"\"\n",
        "        [수정된 Bias 계산]\n",
        "        Bias = (Constraint Bias * Scaling) + (LLR Feedback * Strength)\n",
        "        \"\"\"\n",
        "        N = self.N\n",
        "        \n",
        "        # 1. 제약 조건에 의한 Bias (Constraint)\n",
        "        # lambda_sum_bias calculation (Eq 1.2 logic)\n",
        "        sum_rho_t = np.sum(self.tilde_rho, axis=1, keepdims=True)\n",
        "        constraint_bias = -self.tilde_rho + ((N - 1) / N) * sum_rho_t\n",
        "        \n",
        "        # 2. LLR에 의한 Feedback (Reinforcement)\n",
        "        # 이전 턴에서 '확률이 높다'고 판단된 경로에 가산점 부여\n",
        "        llr_bias = self.last_llr\n",
        "        \n",
        "        # 3. 최종 Bias 결합\n",
        "        # 제약 조건은 아주 약하게(scaling), 확신은 적당하게(feedback)\n",
        "        total_bias = (constraint_bias * self.scaling_factor) + (llr_bias * self.feedback_strength)\n",
        "        \n",
        "        return total_bias\n",
        "\n",
        "    def _run_trellis(self):\n",
        "        N, S, depot = self.N, self.S, self.depot\n",
        "        \n",
        "        # LLR이 포함된 Bias 계산\n",
        "        bias = self._calc_total_bias()\n",
        "        \n",
        "        # --- Forward (Alpha) ---\n",
        "        alpha = [defaultdict(lambda: -INF) for _ in range(N + 1)]\n",
        "        alpha[0][(0, depot)] = 0.0\n",
        "        \n",
        "        for t in range(N):\n",
        "            current_bias = bias[t]\n",
        "            for state, prev_score in alpha[t].items():\n",
        "                if prev_score < -INF / 2: continue\n",
        "                mask, prev_node = state\n",
        "                for i in range(N):\n",
        "                    if not (mask & (1 << i)):\n",
        "                        new_mask = mask | (1 << i)\n",
        "                        # Score = Similarity + Bias(Constraint + LLR)\n",
        "                        val = prev_score + S[prev_node, i] + current_bias[i]\n",
        "                        \n",
        "                        if val > alpha[t+1][(new_mask, i)]:\n",
        "                            alpha[t+1][(new_mask, i)] = val\n",
        "                            \n",
        "        # --- Backward (Beta) ---\n",
        "        beta = [defaultdict(lambda: -INF) for _ in range(N + 2)]\n",
        "        final_mask = (1 << N) - 1\n",
        "        for i in range(N):\n",
        "            beta[N][(final_mask, i)] = S[i, depot]\n",
        "            \n",
        "        for t in range(N - 1, -1, -1):\n",
        "            for next_state, next_beta_val in beta[t+1].items():\n",
        "                if next_beta_val < -INF / 2: continue\n",
        "                next_mask, next_node = next_state\n",
        "                prev_mask = next_mask & ~(1 << next_node)\n",
        "                \n",
        "                # Backward에서도 동일한 Bias 적용\n",
        "                xi_val = next_beta_val + bias[t][next_node]\n",
        "                \n",
        "                cands = [depot] if prev_mask == 0 else [j for j in range(N) if prev_mask & (1<<j)]\n",
        "                for prev in cands:\n",
        "                    val = S[prev, next_node] + xi_val\n",
        "                    if val > beta[t][(prev_mask, prev)]:\n",
        "                        beta[t][(prev_mask, prev)] = val\n",
        "\n",
        "        # --- Soft Output (Delta / LLR) Calculation ---\n",
        "        tilde_delta = np.zeros((N, N))\n",
        "        for t in range(N):\n",
        "            for i in range(N):\n",
        "                max_in = -INF\n",
        "                max_out = -INF\n",
        "                \n",
        "                # Delta 계산 시에는 순수 Constraint 메시지만 빼주는 것이 논리적임\n",
        "                # (Bias에 LLR이 섞여있으므로, 중복 제거를 위해 고려)\n",
        "                # 하지만, 여기서는 근사적으로 Constraint 부분만 제거\n",
        "                \n",
        "                rho_val = self.tilde_rho[t, i] * self.scaling_factor\n",
        "                lam_i_for_i = -(1.0/N) * rho_val\n",
        "                lam_i_for_j = ((N-1.0)/N) * rho_val\n",
        "\n",
        "                for state, f_score in alpha[t+1].items():\n",
        "                    if f_score < -INF / 2: continue\n",
        "                    if state not in beta[t+1]: continue\n",
        "                    b_score = beta[t+1][state]\n",
        "                    if b_score < -INF / 2: continue\n",
        "                    \n",
        "                    total_score = f_score + b_score\n",
        "                    current_city = state[1]\n",
        "                    \n",
        "                    if current_city == i:\n",
        "                        zeta = total_score - lam_i_for_i\n",
        "                        if zeta > max_in: max_in = zeta\n",
        "                    else:\n",
        "                        zeta = total_score - lam_i_for_j\n",
        "                        if zeta > max_out: max_out = zeta\n",
        "                \n",
        "                if max_in < -INF / 2: diff = -INF\n",
        "                elif max_out < -INF / 2: diff = INF\n",
        "                else: diff = max_in - max_out\n",
        "                \n",
        "                tilde_delta[t, i] = diff\n",
        "        \n",
        "        # [중요] 다음 턴을 위해 LLR 저장 (Feedback Loop)\n",
        "        # 값이 너무 커지는 것을 막기 위해 클리핑 가능 (선택사항)\n",
        "        self.last_llr = np.clip(tilde_delta, -1e5, 1e5)\n",
        "                \n",
        "        return alpha, tilde_delta\n",
        "\n",
        "    def _run_bp(self, tilde_delta):\n",
        "        N = self.N\n",
        "        \n",
        "        # BP Update (Standard)\n",
        "        t_omega = self.tilde_phi + tilde_delta\n",
        "        \n",
        "        new_eta = np.zeros_like(self.tilde_eta)\n",
        "        for i in range(N):\n",
        "            for t in range(N):\n",
        "                mask = np.ones(N, dtype=bool)\n",
        "                mask[t] = False\n",
        "                new_eta[t, i] = -np.max(t_omega[mask, i])\n",
        "                \n",
        "        t_gamma = new_eta + tilde_delta\n",
        "        new_phi = np.zeros_like(self.tilde_phi)\n",
        "        for t in range(N):\n",
        "            for i in range(N):\n",
        "                mask = np.ones(N, dtype=bool)\n",
        "                mask[i] = False\n",
        "                new_phi[t, i] = -np.max(t_gamma[t, mask])\n",
        "        \n",
        "        self.tilde_eta = self.damping * self.tilde_eta + (1 - self.damping) * new_eta\n",
        "        self.tilde_phi = self.damping * self.tilde_phi + (1 - self.damping) * new_phi\n",
        "        self.tilde_rho = self.tilde_eta + self.tilde_phi\n",
        "\n",
        "    def _extract_path(self, alpha):\n",
        "        path = []\n",
        "        curr_mask = (1 << self.N) - 1\n",
        "        best_score = -INF\n",
        "        best_last = -1\n",
        "        \n",
        "        for i in range(self.N):\n",
        "            state = (curr_mask, i)\n",
        "            if state in alpha[self.N]:\n",
        "                if alpha[self.N][state] < -INF / 2: continue\n",
        "                score = alpha[self.N][state] + self.S[i, self.depot]\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_last = i\n",
        "        \n",
        "        if best_last == -1: return [], INF\n",
        "        \n",
        "        path = [self.depot, best_last]\n",
        "        curr_node = best_last\n",
        "        \n",
        "        # Traceback용 Bias도 동일하게 계산\n",
        "        bias = self._calc_total_bias()\n",
        "        \n",
        "        for t in range(self.N - 1, 0, -1):\n",
        "            prev_mask = curr_mask & ~(1 << curr_node)\n",
        "            best_prev = -1\n",
        "            max_val = -INF\n",
        "            cands = [self.depot] if prev_mask == 0 else [j for j in range(self.N) if prev_mask & (1<<j)]\n",
        "            \n",
        "            current_step_bias = bias[t][curr_node]\n",
        "            for prev in cands:\n",
        "                state = (0, prev) if prev == self.depot else (prev_mask, prev)\n",
        "                if state in alpha[t]:\n",
        "                    if alpha[t][state] < -INF / 2: continue\n",
        "                    val = alpha[t][state] + self.S[prev, curr_node] + current_step_bias\n",
        "                    if val > max_val:\n",
        "                        max_val = val\n",
        "                        best_prev = prev\n",
        "            path.append(best_prev)\n",
        "            curr_node = best_prev\n",
        "            curr_mask = prev_mask\n",
        "            \n",
        "        path.append(self.depot)\n",
        "        path.reverse()\n",
        "        cost = 0\n",
        "        for k in range(len(path)-1):\n",
        "            cost += self.dist_matrix[path[k], path[k+1]]\n",
        "        return path, cost\n",
        "\n",
        "    def solve(self):\n",
        "        best_global_path = []\n",
        "        best_global_cost = INF\n",
        "        \n",
        "        print(f\"Solving with LLR Feedback (Constraint Scale={self.scaling_factor}, LLR Strength={self.feedback_strength})\")\n",
        "        \n",
        "        for it in range(self.bp_iterations):\n",
        "            alpha, tilde_delta = self._run_trellis()\n",
        "            path, cost = self._extract_path(alpha)\n",
        "            \n",
        "            if cost < best_global_cost:\n",
        "                best_global_cost = cost\n",
        "                best_global_path = path\n",
        "                print(f\"[Iter {it}] Cost: {cost:.2f} (New Best!) | Lock-in Activated\")\n",
        "            else:\n",
        "                if self.verbose:\n",
        "                     print(f\"[Iter {it}] Cost: {cost:.2f}\")\n",
        "\n",
        "            self._run_bp(tilde_delta)\n",
        "            \n",
        "        return best_global_path, best_global_cost\n",
        "\n",
        "# --- 실행 ---\n",
        "if __name__ == \"__main__\":\n",
        "    # 데이터는 기존과 동일\n",
        "    D = [\n",
        "        [0, 10, 15, 20],\n",
        "        [10, 0, 35, 25],\n",
        "        [15, 35, 0, 30],\n",
        "        [20, 25, 30, 0]\n",
        "    ]\n",
        "    \n",
        "    D = np.random.rand(14,14) * 100\n",
        "    # 1. 제약 조건 간섭 최소화 (scaling=0.01)\n",
        "    # 2. 찾은 경로 강력 고정 (feedback=0.5)\n",
        "    solver = TSPSolverLLRFeedback(D, bp_iterations=20, scaling_factor=0.04, feedback_strength=0.5)\n",
        "    path, cost = solver.solve()\n",
        "    print(f\"\\nFinal Result: {path}, Cost: {cost}\")\n",
        "    \n",
        "    solver2 = TSPBitmask(D)\n",
        "    path2, cost2 = solver2.run()\n",
        "    print(f\"\\nBitmask Result: {path2}, Cost: {cost2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Iter 0] Cost=183.3275\n",
            "[Iter 1] Cost=183.3275\n",
            "[Iter 2] Cost=183.3275\n",
            "[Iter 3] Cost=183.3275\n",
            "[Iter 4] Cost=183.3275\n",
            "[Iter 5] Cost=183.3275\n",
            "[Iter 6] Cost=183.3275\n",
            "[Iter 7] Cost=183.3275\n",
            "[Iter 8] Cost=183.3275\n",
            "[Iter 9] Cost=183.3275\n",
            "[Iter 10] Cost=183.3275\n",
            "[Iter 11] Cost=183.3275\n",
            "[Iter 12] Cost=183.3275\n",
            "[Iter 13] Cost=183.3275\n",
            "[Iter 14] Cost=183.3275\n",
            "[Iter 15] Cost=183.3275\n",
            "[Iter 16] Cost=183.3275\n",
            "[Iter 17] Cost=183.3275\n",
            "[Iter 18] Cost=183.3275\n",
            "[Iter 19] Cost=183.3275\n",
            "\n",
            "Final Result: [13, 8, 5, 11, 7, 10, 4, 6, 3, 1, 2, 9, 12, 0, 13], Cost: 183.32747241717155\n",
            "\n",
            "Bitmask Result: [13, 8, 5, 11, 7, 10, 4, 6, 3, 1, 2, 9, 12, 0, 13], Cost: 183.32747241717155\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "NEG = -1e15   # numerical -inf for safety\n",
        "\n",
        "\n",
        "class TSP_PDF_SOVA_Viterbi:\n",
        "    \"\"\"\n",
        "    PDF-style iterative TSP solver using:\n",
        "    - Pure DP trellis ψ\n",
        "    - α = ψ + λ\n",
        "    - β backward with λ\n",
        "    - SOVA soft output δ̃\n",
        "    - Gauge-fixed λ update\n",
        "    - Viterbi MAP decoding through ψ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dist, damping=0.5, verbose=True):\n",
        "        \"\"\"\n",
        "        dist: (N+1)x(N+1) distance matrix\n",
        "              cities = 0..N-1, depot = N\n",
        "        \"\"\"\n",
        "        self.dist = dist\n",
        "        self.N = dist.shape[0] - 1      # number of cities, last index is depot\n",
        "        self.depot = self.N\n",
        "        self.verbose = verbose\n",
        "        self.damping = damping\n",
        "\n",
        "        # λ[t,i], t=0..N-1, i=0..N-1 (no depot)\n",
        "        self.lam = np.zeros((self.N, self.N))\n",
        "\n",
        "        # Mask range\n",
        "        self.FULL_MASK = (1 << self.N) - 1\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 1) Pure DP ψ computation (no lambda)\n",
        "    # ----------------------------------------------------------------------\n",
        "    def compute_psi(self):\n",
        "        \"\"\"\n",
        "        ψ[t,mask,last], pure DP score (no lambda)\n",
        "        Dimensions:\n",
        "            t = 0..N+1\n",
        "            mask = 0..(1<<N)-1\n",
        "            last = 0..N (including depot)\n",
        "        \"\"\"\n",
        "\n",
        "        # allocate\n",
        "        psi = [\n",
        "            [\n",
        "                np.full(self.N + 1, NEG)  # last=0..N\n",
        "                for _ in range(1 << self.N)\n",
        "            ]\n",
        "            for _ in range(self.N + 2)\n",
        "        ]\n",
        "\n",
        "        # t=0: start at depot, mask=0\n",
        "        psi[0][0][self.depot] = 0.0\n",
        "\n",
        "        # t=1: visit each city i\n",
        "        for i in range(self.N):\n",
        "            mask = (1 << i)\n",
        "            psi[1][mask][i] = -self.dist[self.depot][i]\n",
        "\n",
        "        # t=1..N-1 transitions\n",
        "        for t in range(1, self.N):\n",
        "            for mask in range(1 << self.N):\n",
        "                if bin(mask).count(\"1\") != t:\n",
        "                    continue\n",
        "\n",
        "                for last in range(self.N):\n",
        "                    if not (mask & (1 << last)):\n",
        "                        continue\n",
        "\n",
        "                    base = psi[t][mask][last]\n",
        "                    if base <= NEG / 2:\n",
        "                        continue\n",
        "\n",
        "                    # expand to next city\n",
        "                    for nxt in range(self.N):\n",
        "                        if (mask & (1 << nxt)):\n",
        "                            continue\n",
        "                        new_mask = mask | (1 << nxt)\n",
        "                        new_val = base - self.dist[last][nxt]\n",
        "                        if new_val > psi[t + 1][new_mask][nxt]:\n",
        "                            psi[t + 1][new_mask][nxt] = new_val\n",
        "\n",
        "        # t=N → t=N+1 (return to depot)\n",
        "        t = self.N\n",
        "        mask = self.FULL_MASK\n",
        "        for last in range(self.N):\n",
        "            base = psi[t][mask][last]\n",
        "            if base <= NEG / 2:\n",
        "                continue\n",
        "            val = base - self.dist[last][self.depot]\n",
        "            if val > psi[t + 1][mask][self.depot]:\n",
        "                psi[t + 1][mask][self.depot] = val\n",
        "\n",
        "        return psi\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 2) Compute α = ψ + λ\n",
        "    # ----------------------------------------------------------------------\n",
        "    def compute_alpha(self, psi):\n",
        "        \"\"\"\n",
        "        α[t][mask][last] = ψ[t][mask][last] + λ[t,last] if last < N else ψ\n",
        "        λ applied for t <= N\n",
        "        \"\"\"\n",
        "        alpha = []\n",
        "        for t in range(self.N + 2):\n",
        "            layer = []\n",
        "            for mask in range(1 << self.N):\n",
        "                arr = np.zeros(self.N + 1)\n",
        "                for last in range(self.N + 1):\n",
        "                    base = psi[t][mask][last]\n",
        "                    if base <= NEG / 2:\n",
        "                        arr[last] = NEG\n",
        "                        continue\n",
        "                    if last < self.N and t <= self.N - 1:\n",
        "                        arr[last] = base + self.lam[t][last]\n",
        "                    else:\n",
        "                        arr[last] = base\n",
        "                layer.append(arr)\n",
        "            alpha.append(layer)\n",
        "        return alpha\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 3) Backward β with λ\n",
        "    # ----------------------------------------------------------------------\n",
        "    def compute_beta(self, psi):\n",
        "        \"\"\"\n",
        "        β[t][mask][last] = best future score (ψ + λ)\n",
        "        \"\"\"\n",
        "        # init\n",
        "        beta = [\n",
        "            [\n",
        "                np.full(self.N + 1, NEG)\n",
        "                for _ in range(1 << self.N)\n",
        "            ]\n",
        "            for _ in range(self.N + 2)\n",
        "        ]\n",
        "\n",
        "        # t=N+1: only depot valid\n",
        "        last_layer = self.N + 1\n",
        "        beta[last_layer] = [\n",
        "            np.full(self.N + 1, NEG) for _ in range(1 << self.N)\n",
        "        ]\n",
        "        beta[last_layer][self.FULL_MASK][self.depot] = 0.0\n",
        "\n",
        "        # backward\n",
        "        for t in range(self.N, -1, -1):\n",
        "            for mask in range(1 << self.N):\n",
        "                c = bin(mask).count(\"1\")\n",
        "                if not (0 <= c <= self.N):\n",
        "                    continue\n",
        "\n",
        "                for last in range(self.N + 1):\n",
        "                    base = psi[t][mask][last]\n",
        "                    if base <= NEG / 2:\n",
        "                        continue\n",
        "\n",
        "                    best = NEG\n",
        "\n",
        "                    # next step\n",
        "                    if c < self.N:\n",
        "                        # visit next city\n",
        "                        for nxt in range(self.N):\n",
        "                            if (mask & (1 << nxt)):\n",
        "                                continue\n",
        "                            new_mask = mask | (1 << nxt)\n",
        "                            val = psi[t + 1][new_mask][nxt]\n",
        "                            if val <= NEG / 2:\n",
        "                                continue\n",
        "                            # add lambda\n",
        "                            if nxt < self.N and (t + 1) <= self.N - 1:\n",
        "                                val += self.lam[t + 1][nxt]\n",
        "                            if val > best:\n",
        "                                best = val\n",
        "\n",
        "                    else:\n",
        "                        # return to depot\n",
        "                        val = psi[t + 1][mask][self.depot]\n",
        "                        if val > best:\n",
        "                            best = val\n",
        "\n",
        "                    beta[t][mask][last] = best\n",
        "\n",
        "        return beta\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 4) SOVA soft output δ̃\n",
        "    # ----------------------------------------------------------------------\n",
        "    def compute_soft_output(self, alpha, beta):\n",
        "        \"\"\"\n",
        "        δ̃[t][i], t=1..N\n",
        "        ζ[t][i] = max over states ending at city i of (α+β−λ)\n",
        "        \"\"\"\n",
        "        delta = np.zeros((self.N + 1, self.N))  # time 0..N\n",
        "\n",
        "        for t in range(1, self.N + 1):\n",
        "            z = np.full(self.N, NEG)\n",
        "            for mask in range(1 << self.N):\n",
        "                if bin(mask).count(\"1\") != t:\n",
        "                    continue\n",
        "                for last in range(self.N):\n",
        "                    if not (mask & (1 << last)):\n",
        "                        continue\n",
        "                    val = alpha[t][mask][last] + beta[t][mask][last]\n",
        "                    val -= self.lam[t - 1][last]\n",
        "                    if val > z[last]:\n",
        "                        z[last] = val\n",
        "\n",
        "            # compute δ̃\n",
        "            for i in range(self.N):\n",
        "                others = np.delete(z, i)\n",
        "                delta[t][i] = z[i] - np.max(others)\n",
        "\n",
        "        return delta\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 5) λ update with gauge fix\n",
        "    # ----------------------------------------------------------------------\n",
        "    def update_lambda(self, delta):\n",
        "        \"\"\"\n",
        "        λ[t,i] = λ[t,i] + damping * (row_sum − N*delta)\n",
        "        then gauge-fix mean subtraction\n",
        "        \"\"\"\n",
        "        for t in range(self.N):\n",
        "            rho = delta[t + 1]   # shift: delta is t=1..N\n",
        "            row_sum = np.sum(rho)\n",
        "            update = row_sum - self.N * rho\n",
        "            self.lam[t] += self.damping * update\n",
        "            # gauge fix\n",
        "            self.lam[t] -= np.mean(self.lam[t])\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 6) Viterbi MAP decoding on ψ\n",
        "    # ----------------------------------------------------------------------\n",
        "    def decode_path(self, psi):\n",
        "            \"\"\"\n",
        "            Backtracking the best path using ψ (Corrected Logic)\n",
        "            \"\"\"\n",
        "            # 1. 마지막 상태 (Depot 도착 직전)\n",
        "            curr = self.depot\n",
        "            # t=N+1에서의 점수 (최종 점수)\n",
        "            current_val = psi[self.N + 1][self.FULL_MASK][self.depot]\n",
        "            \n",
        "            if current_val <= NEG / 2:\n",
        "                raise RuntimeError(\"No valid final state.\")\n",
        "\n",
        "            path = [0] * (self.N + 2)\n",
        "            path[self.N + 1] = self.depot # 마지막은 Depot\n",
        "\n",
        "            # 현재 방문한 도시들의 집합 (초기엔 모든 도시 방문 상태)\n",
        "            mask = self.FULL_MASK\n",
        "\n",
        "            # 2. t = N 부터 1 까지 역추적\n",
        "            for t in range(self.N, 0, -1):\n",
        "                found = False\n",
        "                \n",
        "                # 마스크에 포함된(방문했던) 도시들 중, 현재 도시(curr)로 올 수 있는 'prev' 찾기\n",
        "                for prev in range(self.N):\n",
        "                    if (mask >> prev) & 1:\n",
        "                        # 후보 점수 가져오기\n",
        "                        prev_val = psi[t][mask][prev]\n",
        "                        \n",
        "                        # 검증 식: (이전 누적 점수) - (이동 거리) == (현재 누적 점수)\n",
        "                        # 부동소수점 오차를 고려해 np.isclose 사용\n",
        "                        if np.isclose(prev_val - self.dist[prev][curr], current_val):\n",
        "                            path[t] = prev      # 경로 기록\n",
        "                            current_val = prev_val # 점수 갱신 (다음 단계 검증용)\n",
        "                            curr = prev         # 현재 위치 이동\n",
        "                            mask ^= (1 << prev) # 마스크에서 해당 도시 제거\n",
        "                            found = True\n",
        "                            break\n",
        "                \n",
        "                if not found:\n",
        "                    print(f\"Backtracking failed at t={t}\")\n",
        "                    return None, 0.0\n",
        "\n",
        "            path[0] = self.depot # 시작점은 Depot\n",
        "            \n",
        "            # Cost는 Max-Sum 문제(음수 거리)로 풀었으므로, 원래 양수 거리로 변환하여 반환\n",
        "            return path, -psi[self.N + 1][self.FULL_MASK][self.depot]\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 7) Full iteration\n",
        "    # ----------------------------------------------------------------------\n",
        "    def solve(self, max_iter=20):\n",
        "        best_path = None\n",
        "        best_cost = 1e18\n",
        "\n",
        "        for it in range(max_iter):\n",
        "            psi = self.compute_psi()\n",
        "            alpha = self.compute_alpha(psi)\n",
        "            beta = self.compute_beta(psi)\n",
        "            delta = self.compute_soft_output(alpha, beta)\n",
        "\n",
        "            self.update_lambda(delta)\n",
        "\n",
        "            path, cost = self.decode_path(psi)\n",
        "\n",
        "            if cost < best_cost:\n",
        "                best_cost = cost\n",
        "                best_path = path\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"[Iter {it}] Cost={cost:.4f}\")\n",
        "\n",
        "        return best_path, best_cost\n",
        "\n",
        "\n",
        "D = [\n",
        "    [0, 10, 15, 20],\n",
        "    [10, 0, 35, 25],\n",
        "    [15, 35, 0, 30],\n",
        "    [20, 25, 30, 0]\n",
        "]\n",
        "N = 14\n",
        "D = np.random.rand(N,N) * 100\n",
        "# 1. 제약 조건 간섭 최소화 (scaling=0.01)\n",
        "# 2. 찾은 경로 강력 고정 (feedback=0.5)\n",
        "solver = TSP_PDF_SOVA_Viterbi(D, verbose=True)\n",
        "path, cost = solver.solve()\n",
        "print(f\"\\nFinal Result: {path}, Cost: {cost}\")\n",
        "\n",
        "solver2 = TSPBitmask(D)\n",
        "path2, cost2 = solver2.run()\n",
        "print(f\"\\nBitmask Result: {path2}, Cost: {cost2}\")\n",
        "\n",
        "def normalize_cycle(path):\n",
        "    \"\"\"\n",
        "    path = [depot, a1, a2, ..., aN, depot]\n",
        "    -> 내부 cycle [a1..aN] 을 rotation-normalized 반환\n",
        "    \"\"\"\n",
        "    # remove depot at both ends\n",
        "    core = path[1:-1]\n",
        "\n",
        "    # rotation normalize (lexicographically smallest rotation)\n",
        "    best = None\n",
        "    for i in range(len(core)):\n",
        "        rot = core[i:] + core[:i]\n",
        "        if best is None or rot < best:\n",
        "            best = rot\n",
        "\n",
        "    # reverse direction normalize도 고려 (TSP cycle은 방향 무관)\n",
        "    rev = core[::-1]\n",
        "    best_rev = None\n",
        "    for i in range(len(rev)):\n",
        "        rot = rev[i:] + rev[:i]\n",
        "        if best_rev is None or rot < best_rev:\n",
        "            best_rev = rot\n",
        "\n",
        "    # 두 방향 중 lexicographically smaller 선택\n",
        "    return min(best, best_rev)\n",
        "\n",
        "def same_tsp_tour(path1, path2):\n",
        "    return normalize_cycle(path1) == normalize_cycle(path2)\n",
        "\n",
        "print(same_tsp_tour(path, path2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Iter 0] Cost: 176.2363 | Valid: True\n",
            "[Iter 1] Cost: 176.2363 | Valid: True\n",
            "[Iter 2] Cost: 176.2363 | Valid: True\n",
            "[Iter 3] Cost: 176.2363 | Valid: True\n",
            "[Iter 4] Cost: 176.2363 | Valid: True\n",
            "[Iter 5] Cost: 176.2363 | Valid: True\n",
            "[Iter 6] Cost: 176.2363 | Valid: True\n",
            "[Iter 7] Cost: 176.2363 | Valid: True\n",
            "[Iter 8] Cost: 176.2363 | Valid: True\n",
            "[Iter 9] Cost: 183.6319 | Valid: True\n",
            "[Iter 10] Cost: 183.6319 | Valid: True\n",
            "[Iter 11] Cost: 183.6319 | Valid: True\n",
            "[Iter 12] Cost: 183.6319 | Valid: True\n",
            "[Iter 13] Cost: 183.6319 | Valid: True\n",
            "[Iter 14] Cost: 183.6319 | Valid: True\n",
            "[Iter 15] Cost: 183.6319 | Valid: True\n",
            "[Iter 16] Cost: 183.6319 | Valid: True\n",
            "[Iter 17] Cost: 183.6319 | Valid: True\n",
            "[Iter 18] Cost: 183.6319 | Valid: True\n",
            "[Iter 19] Cost: 183.6319 | Valid: True\n",
            "\n",
            "✅ Final Result\n",
            "Path: [0, 6, 8, 3, 5, 7, 2, 4, 9, 1, 0]\n",
            "Cost: 176.23632076508383\n",
            "\n",
            "Bitmask Result: [9, 1, 0, 6, 8, 3, 5, 7, 2, 4, 9], Cost: 176.23632076508383\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "####### 지금 기준으로 얘가 제일 잘 된#########\n",
        "\n",
        "class TSP_PDF_Exact_Solver_Final:\n",
        "    def __init__(self, dist_matrix, damping=0.5, verbose=True):\n",
        "        self.dist = dist_matrix\n",
        "        self.N = dist_matrix.shape[0]\n",
        "        self.damping = damping\n",
        "        self.verbose = verbose\n",
        "        self.lam = np.zeros((self.N, self.N)) \n",
        "\n",
        "    def solve(self, max_iter=100):\n",
        "        if self.N > 18:\n",
        "            print(\"Warning: N is too large for Exact Bitmask DP.\")\n",
        "\n",
        "        best_path = None\n",
        "        best_cost = float('inf')\n",
        "\n",
        "        for it in range(max_iter):\n",
        "            # 1. Forward Alpha (DP 채우기)\n",
        "            alpha = self._run_forward_alpha_mask()\n",
        "            \n",
        "            # 2. Backward Beta\n",
        "            beta = self._run_backward_beta_mask()\n",
        "\n",
        "            # 3. Soft Output (LLR)\n",
        "            delta_tilde = self._compute_soft_output_mask(alpha, beta)\n",
        "\n",
        "            # 4. Decoding (Alpha 기반 역추적)\n",
        "            current_path, current_cost = self._decode_path_mask(alpha)\n",
        "            \n",
        "            # 검증 로직 수정: 집합의 크기는 N이어야 함 (0이 시작과 끝에 있으므로)\n",
        "            is_valid = (len(set(current_path)) == self.N) and (current_path[0] == 0) and (current_path[-1] == 0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print(f\"[Iter {it}] Cost: {current_cost:.4f} | Valid: {is_valid}\")\n",
        "\n",
        "            if is_valid and current_cost < best_cost:\n",
        "                best_cost = current_cost\n",
        "                best_path = current_path\n",
        "            \n",
        "            # 5. Lambda Update (NaN 방지 적용)\n",
        "            update_term = self._compute_lambda_update(delta_tilde)\n",
        "            self.lam = self.lam + self.damping * update_term\n",
        "\n",
        "        return best_path, best_cost\n",
        "\n",
        "    def _get_edge_weight(self, t, u, v):\n",
        "        # t 시점에 u -> v 로 이동\n",
        "        # lambda는 '방문하는 도시 v'와 '시간 t'에 걸림\n",
        "        return -self.dist[u, v] + self.lam[t, v]\n",
        "\n",
        "    def _run_forward_alpha_mask(self):\n",
        "        dim_mask = 1 << self.N\n",
        "        alpha = np.full((dim_mask, self.N), -np.inf)\n",
        "        \n",
        "        # 시작점: 0번 도시, mask = 0...01\n",
        "        alpha[1][0] = 0\n",
        "        \n",
        "        # mask 크기 1부터 2^N-1까지 순회\n",
        "        for mask in range(1, dim_mask):\n",
        "            # 현재 방문한 도시 수 (t)\n",
        "            # 예: N=5, mask가 11111(31)이면 t=5. 더 이상 갈 곳 없음.\n",
        "            t = bin(mask).count('1') \n",
        "            if t == self.N: continue \n",
        "\n",
        "            # 현재 mask 상태의 모든 도시 u에 대해\n",
        "            for u in range(self.N):\n",
        "                if (mask >> u) & 1:\n",
        "                    if alpha[mask][u] == -np.inf: continue\n",
        "                    \n",
        "                    # 다음 도시 v 찾기\n",
        "                    for v in range(self.N):\n",
        "                        if not ((mask >> v) & 1): # 미방문 도시\n",
        "                            new_mask = mask | (1 << v)\n",
        "                            # t는 현재 방문한 개수이자, 다음 시간 인덱스 (0-based)\n",
        "                            # u(t-1번째 방문) -> v(t번째 방문)\n",
        "                            weight = self._get_edge_weight(t, u, v)\n",
        "                            \n",
        "                            if alpha[mask][u] + weight > alpha[new_mask][v]:\n",
        "                                alpha[new_mask][v] = alpha[mask][u] + weight\n",
        "        return alpha\n",
        "\n",
        "    def _run_backward_beta_mask(self):\n",
        "        dim_mask = 1 << self.N\n",
        "        beta = np.full((dim_mask, self.N), -np.inf)\n",
        "        \n",
        "        # Base Case: Full Mask 상태에서 0번으로 돌아가는 비용\n",
        "        full_mask = (1 << self.N) - 1\n",
        "        for u in range(1, self.N):\n",
        "            # 마지막 단계는 lambda 적용 안 함 (혹은 t=N lambda가 0이라고 가정)\n",
        "            # 순수 거리 비용만 차감\n",
        "            beta[full_mask][u] = -self.dist[u, 0]\n",
        "\n",
        "        # 역방향 진행\n",
        "        for mask in range(dim_mask - 1, 0, -1):\n",
        "            t = bin(mask).count('1')\n",
        "            if t == self.N: continue # Full mask는 이미 처리됨\n",
        "\n",
        "            for u in range(self.N):\n",
        "                if (mask >> u) & 1:\n",
        "                    scores = []\n",
        "                    for v in range(self.N):\n",
        "                        if not ((mask >> v) & 1):\n",
        "                            next_mask = mask | (1 << v)\n",
        "                            # Forward와 동일한 가중치 사용: u -> v (시간 t)\n",
        "                            weight = self._get_edge_weight(t, u, v)\n",
        "                            \n",
        "                            if beta[next_mask][v] != -np.inf:\n",
        "                                scores.append(weight + beta[next_mask][v])\n",
        "                    \n",
        "                    if scores:\n",
        "                        beta[mask][u] = np.max(scores)\n",
        "        return beta\n",
        "\n",
        "    def _compute_soft_output_mask(self, alpha, beta):\n",
        "        delta_tilde = np.full((self.N, self.N), -np.inf)\n",
        "        dim_mask = 1 << self.N\n",
        "        \n",
        "        # Marginalization\n",
        "        # delta[t][i] = max(Path passing i at t) - max(Path NOT passing i at t)\n",
        "        \n",
        "        # 1. Collect scores for passing i at time t\n",
        "        scores_in = { (t, i): -np.inf for t in range(self.N) for i in range(self.N) }\n",
        "        \n",
        "        for mask in range(1, dim_mask):\n",
        "            t = bin(mask).count('1') - 1 # 시간 인덱스 (0~N-1)\n",
        "            if t >= self.N: continue\n",
        "\n",
        "            for u in range(self.N):\n",
        "                if (mask >> u) & 1:\n",
        "                    val = alpha[mask][u] + beta[mask][u]\n",
        "                    if val > scores_in[(t, u)]:\n",
        "                        scores_in[(t, u)] = val\n",
        "\n",
        "        # 2. Compute Delta\n",
        "        for t in range(self.N):\n",
        "            # t시점 전체 Max Score (Normalizer 역할)\n",
        "            row_max = -np.inf\n",
        "            for i in range(self.N):\n",
        "                if scores_in[(t, i)] > row_max:\n",
        "                    row_max = scores_in[(t, i)]\n",
        "            \n",
        "            if row_max == -np.inf: continue # 해당 시간대 도달 불가 (있을 수 없음)\n",
        "\n",
        "            for i in range(self.N):\n",
        "                score_in = scores_in[(t, i)]\n",
        "                \n",
        "                # score_out: i가 아닌 다른 노드를 방문했을 때의 최대값\n",
        "                score_out = -np.inf\n",
        "                for j in range(self.N):\n",
        "                    if i == j: continue\n",
        "                    if scores_in[(t, j)] > score_out:\n",
        "                        score_out = scores_in[(t, j)]\n",
        "                \n",
        "                # 안전한 뺄셈 (Inf - Inf 방지)\n",
        "                if score_in == -np.inf and score_out == -np.inf:\n",
        "                    delta_tilde[t, i] = 0 # 의미 없음\n",
        "                elif score_in == -np.inf:\n",
        "                    delta_tilde[t, i] = -1e9 # 매우 낮은 값 (선택 안 함)\n",
        "                elif score_out == -np.inf:\n",
        "                    delta_tilde[t, i] = 1e9 # 무조건 선택\n",
        "                else:\n",
        "                    delta_tilde[t, i] = score_in - score_out\n",
        "                    \n",
        "        return delta_tilde\n",
        "\n",
        "    def _compute_lambda_update(self, delta_tilde):\n",
        "        update_matrix = np.zeros_like(delta_tilde)\n",
        "        for t in range(self.N):\n",
        "            rho_vec = delta_tilde[t, :]\n",
        "            \n",
        "            # 유효한 값들만 필터링하여 합계 계산\n",
        "            valid_indices = np.where((rho_vec > -1e8) & (rho_vec < 1e8))[0]\n",
        "            if len(valid_indices) == 0: continue\n",
        "            \n",
        "            sum_rho = np.sum(rho_vec[valid_indices])\n",
        "            \n",
        "            for i in range(self.N):\n",
        "                # 값이 너무 크거나 작으면 업데이트 건너뜀 (안정성)\n",
        "                if abs(rho_vec[i]) > 1e8: \n",
        "                    continue\n",
        "                \n",
        "                sum_others = sum_rho - rho_vec[i]\n",
        "                update_matrix[t, i] = -rho_vec[i] + sum_others\n",
        "                \n",
        "        return update_matrix\n",
        "\n",
        "    def _decode_path_mask(self, alpha):\n",
        "        # 1. 마지막 단계 (Full Mask) 찾기\n",
        "        full_mask = (1 << self.N) - 1\n",
        "        best_last = -1\n",
        "        best_val = -np.inf\n",
        "        \n",
        "        for u in range(1, self.N):\n",
        "            # alpha 값 + 돌아가는 거리\n",
        "            val = alpha[full_mask][u] - self.dist[u, 0]\n",
        "            if val > best_val:\n",
        "                best_val = val\n",
        "                best_last = u\n",
        "                \n",
        "        if best_last == -1:\n",
        "            return [0], float('inf')\n",
        "\n",
        "        # 2. 역추적\n",
        "        path = [best_last]\n",
        "        curr_mask = full_mask\n",
        "        curr_node = best_last\n",
        "        \n",
        "        while curr_mask != 1: # 시작점(1)만 남을 때까지\n",
        "            t = bin(curr_mask).count('1') - 1\n",
        "            prev_mask = curr_mask ^ (1 << curr_node)\n",
        "            \n",
        "            # 이전 노드 찾기\n",
        "            found = False\n",
        "            for prev_u in range(self.N):\n",
        "                if (prev_mask >> prev_u) & 1:\n",
        "                    weight = self._get_edge_weight(t, prev_u, curr_node)\n",
        "                    if np.isclose(alpha[prev_mask][prev_u] + weight, alpha[curr_mask][curr_node]):\n",
        "                        path.append(prev_u)\n",
        "                        curr_node = prev_u\n",
        "                        curr_mask = prev_mask\n",
        "                        found = True\n",
        "                        break\n",
        "            if not found: break\n",
        "            \n",
        "        path.reverse() # [0, ..., last]\n",
        "        full_path = path + [0] # [0, ..., last, 0]\n",
        "        \n",
        "        # 3. 실제 비용 계산\n",
        "        real_cost = 0\n",
        "        if len(set(full_path)) == self.N and full_path[0]==0 and full_path[-1]==0:\n",
        "            for i in range(len(full_path)-1):\n",
        "                real_cost += self.dist[full_path[i], full_path[i+1]]\n",
        "        else:\n",
        "            real_cost = float('inf')\n",
        "            \n",
        "        return full_path, real_cost\n",
        "\n",
        "# --- 실행 ---\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    N = 10 \n",
        "    coords = np.random.rand(N, 2) * 100\n",
        "    '''dist_matrix = np.zeros((N, N))\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            dist_matrix[i, j] = np.linalg.norm(coords[i] - coords[j])'''\n",
        "    dist_matrix = np.random.rand(N, N) * 100\n",
        "\n",
        "    solver = TSP_PDF_Exact_Solver_Final(dist_matrix, damping=0.02) # Damping 낮춤 (안정성)\n",
        "    best_path, best_cost = solver.solve(max_iter=20)\n",
        "    \n",
        "    print(\"\\n✅ Final Result\")\n",
        "    print(\"Path:\", best_path)\n",
        "    print(\"Cost:\", best_cost)\n",
        "    \n",
        "    solver2 = TSPBitmask(dist_matrix)\n",
        "    path2, cost2 = solver2.run()\n",
        "    print(f\"\\nBitmask Result: {path2}, Cost: {cost2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Ground Truth (Held-Karp Exact) ===\n",
            "Path : [10, 1, 2, 5, 0, 6, 9, 8, 7, 3, 4, 10]\n",
            "Cost : 389.15632499622393\n",
            "[Iter 0] Cost = 389.156325\n",
            "[Iter 1] Cost = 389.156325\n",
            "[Iter 2] Cost = 389.156325\n",
            "[Iter 3] Cost = 389.156325\n",
            "[Iter 4] Cost = 389.156325\n",
            "[Iter 5] Cost = 389.156325\n",
            "[Iter 6] Cost = 389.156325\n",
            "[Iter 7] Cost = 389.156325\n",
            "[Iter 8] Cost = 389.156325\n",
            "[Iter 9] Cost = 389.156325\n",
            "\n",
            "=== PDF-SOVA-Viterbi Result ===\n",
            "Path : [10, 1, 2, 5, 0, 6, 9, 8, 7, 3, 4, 10]\n",
            "Cost : 389.15632499622393\n",
            "\n",
            "=== CHECK ===\n",
            "Cost match?     True\n",
            "Ordering match? True\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "NEG = -1e15   # numerical negative infinity\n",
        "\n",
        "\n",
        "class TSP_PDF_SOVA_Viterbi_Final:\n",
        "    \"\"\"\n",
        "    Full PDF-based TSP Turbo Solver:\n",
        "        - Held–Karp ψ DP (exact)\n",
        "        - α = ψ + λ\n",
        "        - β backward DP (PDF style)\n",
        "        - δ̃ SOVA soft output\n",
        "        - λ update + gauge fix\n",
        "        - Final MAP Viterbi decoding (ψ+λ)\n",
        "\n",
        "    Cities = 0..N-1, Depot = N.\n",
        "    dist is (N+1)x(N+1).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dist, damping=0.5, verbose=True):\n",
        "        self.dist = np.array(dist)\n",
        "        self.N = dist.shape[0] - 1\n",
        "        self.depot = self.N\n",
        "        self.verbose = verbose\n",
        "        self.damping = damping\n",
        "\n",
        "        # λ[t,i], t=1..N, i=0..N-1\n",
        "        self.lam = np.zeros((self.N + 1, self.N))\n",
        "\n",
        "        self.FULL_MASK = (1 << self.N) - 1\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # 1) Held–Karp ψ DP\n",
        "    # ---------------------------------------------------------------------\n",
        "    def compute_psi(self):\n",
        "        \"\"\"\n",
        "        ψ[t][mask][last]:\n",
        "            best score (max-sum) for visiting exactly t cities,\n",
        "            visited=mask, ending at last.\n",
        "        \"\"\"\n",
        "\n",
        "        # allocate\n",
        "        psi = [\n",
        "            [\n",
        "                np.full(self.N + 1, NEG)\n",
        "                for _ in range(1 << self.N)\n",
        "            ]\n",
        "            for _ in range(self.N + 2)\n",
        "        ]\n",
        "\n",
        "        # t=0: start at depot, mask=0\n",
        "        psi[0][0][self.depot] = 0.0\n",
        "\n",
        "        # t=1: visit each city directly from depot\n",
        "        for i in range(self.N):\n",
        "            m = (1 << i)\n",
        "            psi[1][m][i] = -self.dist[self.depot][i]\n",
        "\n",
        "        # t = 1..N-1\n",
        "        for t in range(1, self.N):\n",
        "            for mask in range(1 << self.N):\n",
        "                if bin(mask).count(\"1\") != t:\n",
        "                    continue\n",
        "                for last in range(self.N):\n",
        "                    if not (mask & (1 << last)):\n",
        "                        continue\n",
        "                    base = psi[t][mask][last]\n",
        "                    if base <= NEG/2:\n",
        "                        continue\n",
        "                    # expand\n",
        "                    for nxt in range(self.N):\n",
        "                        if mask & (1 << nxt):\n",
        "                            continue\n",
        "                        new_mask = mask | (1 << nxt)\n",
        "                        val = base - self.dist[last][nxt]\n",
        "                        if val > psi[t+1][new_mask][nxt]:\n",
        "                            psi[t+1][new_mask][nxt] = val\n",
        "\n",
        "        # t=N → return to depot\n",
        "        mask = self.FULL_MASK\n",
        "        t = self.N\n",
        "        for last in range(self.N):\n",
        "            base = psi[t][mask][last]\n",
        "            if base > NEG/2:\n",
        "                val = base - self.dist[last][self.depot]\n",
        "                if val > psi[t+1][mask][self.depot]:\n",
        "                    psi[t+1][mask][self.depot] = val\n",
        "\n",
        "        return psi\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # 2) α = ψ + λ\n",
        "    # ---------------------------------------------------------------------\n",
        "    def compute_alpha(self, psi):\n",
        "        \"\"\"\n",
        "        α[t][mask][last] = ψ[t][mask][last] + λ[t][last] (if last<dep)\n",
        "        \"\"\"\n",
        "        alpha = []\n",
        "        for t in range(self.N + 2):\n",
        "            layer = []\n",
        "            for mask in range(1 << self.N):\n",
        "                arr = np.zeros(self.N + 1)\n",
        "                for last in range(self.N + 1):\n",
        "                    base = psi[t][mask][last]\n",
        "                    if base <= NEG/2:\n",
        "                        arr[last] = NEG\n",
        "                        continue\n",
        "                    if last < self.N and 1 <= t <= self.N:\n",
        "                        arr[last] = base + self.lam[t][last]\n",
        "                    else:\n",
        "                        arr[last] = base\n",
        "                layer.append(arr)\n",
        "            alpha.append(layer)\n",
        "        return alpha\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # 3) β backward DP (PDF-style)\n",
        "    # ---------------------------------------------------------------------\n",
        "    def compute_beta(self, psi):\n",
        "        \"\"\"\n",
        "        β[t][mask][last] = best future score from (t,mask,last)\n",
        "        using ψ and λ, following PDF backward recursion.\n",
        "        \"\"\"\n",
        "        beta = [\n",
        "            [\n",
        "                np.full(self.N + 1, NEG)\n",
        "                for _ in range(1 << self.N)\n",
        "            ]\n",
        "            for _ in range(self.N + 2)\n",
        "        ]\n",
        "\n",
        "        # Terminal layer: t = N+1 — only depot valid\n",
        "        beta[self.N + 1][self.FULL_MASK][self.depot] = 0.0\n",
        "\n",
        "        # Backward t = N ... 0\n",
        "        for t in range(self.N, -1, -1):\n",
        "            for mask in range(1 << self.N):\n",
        "                c = bin(mask).count(\"1\")\n",
        "                if c > self.N:\n",
        "                    continue\n",
        "\n",
        "                for last in range(self.N + 1):\n",
        "                    base = psi[t][mask][last]\n",
        "                    if base <= NEG/2:\n",
        "                        continue\n",
        "\n",
        "                    best = NEG\n",
        "\n",
        "                    if c < self.N:\n",
        "                        # expand to next city\n",
        "                        for nxt in range(self.N):\n",
        "                            if mask & (1 << nxt):\n",
        "                                continue\n",
        "                            new_mask = mask | (1 << nxt)\n",
        "\n",
        "                            val = psi[t+1][new_mask][nxt]\n",
        "                            if val <= NEG/2:\n",
        "                                continue\n",
        "\n",
        "                            # Add λ message at time t+1, city nxt\n",
        "                            if 1 <= t+1 <= self.N:\n",
        "                                val += self.lam[t+1][nxt]\n",
        "\n",
        "                            if val > best:\n",
        "                                best = val\n",
        "\n",
        "                    else:\n",
        "                        # All cities visited → must return to depot\n",
        "                        val = psi[t+1][mask][self.depot]\n",
        "                        if val > best:\n",
        "                            best = val\n",
        "\n",
        "                    beta[t][mask][last] = best\n",
        "\n",
        "        return beta\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # 4) δ̃ SOVA soft output\n",
        "    # ---------------------------------------------------------------------\n",
        "    def compute_soft_output(self, alpha, beta):\n",
        "        \"\"\"\n",
        "        δ̃[t][i]:\n",
        "            max over all states ending in city i of (α+β−λ)\n",
        "            minus max over states ending in non-i cities\n",
        "\n",
        "        Only defined for t=1..N.\n",
        "        \"\"\"\n",
        "        delta = np.zeros((self.N + 1, self.N))\n",
        "\n",
        "        for t in range(1, self.N + 1):\n",
        "            z = np.full(self.N, NEG)\n",
        "\n",
        "            # gather α+β−λ for states ending at each city\n",
        "            for mask in range(1 << self.N):\n",
        "                if bin(mask).count(\"1\") != t:\n",
        "                    continue\n",
        "                for last in range(self.N):\n",
        "                    if not (mask & (1 << last)):\n",
        "                        continue\n",
        "\n",
        "                    val = alpha[t][mask][last] + beta[t][mask][last] - self.lam[t][last]\n",
        "\n",
        "                    if val > z[last]:\n",
        "                        z[last] = val\n",
        "\n",
        "            # now δ̃[t][i] = z[i] − max(z[j], j≠i)\n",
        "            for i in range(self.N):\n",
        "                others = np.delete(z, i)\n",
        "                if len(others) > 0:\n",
        "                    delta[t][i] = z[i] - np.max(others)\n",
        "                else:\n",
        "                    delta[t][i] = 0.0\n",
        "\n",
        "        return delta\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # 5) λ update + gauge fix\n",
        "    # ---------------------------------------------------------------------\n",
        "    def update_lambda(self, delta):\n",
        "        \"\"\"\n",
        "        λ[t,i] ← λ[t,i] + damping*(sum_j δ̃[t][j] − N*δ̃[t][i])\n",
        "        gauge-fix: subtract mean to keep λ row centered\n",
        "        \"\"\"\n",
        "        for t in range(1, self.N + 1):\n",
        "            rho = delta[t]\n",
        "            s = np.sum(rho)\n",
        "            update = s - self.N * rho\n",
        "            self.lam[t] += self.damping * update\n",
        "            # gauge fix\n",
        "            self.lam[t] -= np.mean(self.lam[t])\n",
        "\n",
        "    # ---------------------------------------------------------------------\n",
        "    # 6) Viterbi MAP decoding using ψ+λ\n",
        "    # ---------------------------------------------------------------------\n",
        "    def decode_path(self, psi):\n",
        "        \"\"\"\n",
        "        Final HK backtracking using ONLY ψ (pure distance DP).\n",
        "        λ, α, β 등은 절대 들어가면 안 된다.\n",
        "\n",
        "        Returns:\n",
        "            path: [depot, ..., depot]\n",
        "            cost: sum of dist along the path\n",
        "        \"\"\"\n",
        "\n",
        "        N = self.N\n",
        "        depot = self.depot\n",
        "        FULL = self.FULL_MASK\n",
        "\n",
        "        # ------------------------------------------------------\n",
        "        # 1) 마지막 도시 찾기 (return-to-depot 포함)\n",
        "        # ------------------------------------------------------\n",
        "        best_last = None\n",
        "        best_score = NEG\n",
        "\n",
        "        for last in range(N):\n",
        "            base = psi[N][FULL][last]\n",
        "            if base <= NEG/2:\n",
        "                continue\n",
        "            \n",
        "            val = base - self.dist[last][depot]\n",
        "            if val > best_score:\n",
        "                best_score = val\n",
        "                best_last = last\n",
        "\n",
        "        if best_last is None:\n",
        "            raise RuntimeError(\"decode_path: no valid final state found\")\n",
        "\n",
        "        # ------------------------------------------------------\n",
        "        # 2) HK Backtracking\n",
        "        # ------------------------------------------------------\n",
        "        mask = FULL\n",
        "        last = best_last\n",
        "\n",
        "        # path indices: 0...N+1 (including depot start/end)\n",
        "        path = [None] * (N + 2)\n",
        "        path[N+1] = depot\n",
        "        path[N] = last\n",
        "\n",
        "        for t in range(N, 0, -1):\n",
        "            prev_best = None\n",
        "            prev_best_score = NEG\n",
        "            prev_mask = mask ^ (1 << last)\n",
        "\n",
        "            if t == 1:\n",
        "                # previous must be depot\n",
        "                prev_best = depot\n",
        "            else:\n",
        "                # choose best predecessor i\n",
        "                for i in range(N):\n",
        "                    if not (prev_mask & (1 << i)):\n",
        "                        continue\n",
        "\n",
        "                    base = psi[t-1][prev_mask][i]\n",
        "                    if base <= NEG/2:\n",
        "                        continue\n",
        "\n",
        "                    val = base - self.dist[i][last]\n",
        "                    if val > prev_best_score:\n",
        "                        prev_best_score = val\n",
        "                        prev_best = i\n",
        "\n",
        "            path[t-1] = prev_best\n",
        "\n",
        "            # update for next step\n",
        "            last = prev_best\n",
        "            mask = prev_mask\n",
        "\n",
        "        # ------------------------------------------------------\n",
        "        # 3) 최종 경로 cost는 반드시 \"dist로 직접 계산\"\n",
        "        # ------------------------------------------------------\n",
        "        final_cost = 0.0\n",
        "        for i in range(N+1):\n",
        "            final_cost += self.dist[path[i]][path[i+1]]\n",
        "\n",
        "        return path, final_cost\n",
        "\n",
        " \n",
        "    # ---------------------------------------------------------------------\n",
        "    # 7) full iteration\n",
        "    # ---------------------------------------------------------------------\n",
        "    def solve(self, max_iter=20):\n",
        "        best_path = None\n",
        "        best_cost = 1e18\n",
        "\n",
        "        for it in range(max_iter):\n",
        "            psi = self.compute_psi()\n",
        "            alpha = self.compute_alpha(psi)\n",
        "            beta = self.compute_beta(psi)\n",
        "            delta = self.compute_soft_output(alpha, beta)\n",
        "\n",
        "            self.update_lambda(delta)\n",
        "\n",
        "            path, cost = self.decode_path(psi)\n",
        "\n",
        "            if cost < best_cost:\n",
        "                best_cost = cost\n",
        "                best_path = path\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f\"[Iter {it}] Cost = {cost:.6f}\")\n",
        "\n",
        "        return best_path, best_cost\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    def make_random_tsp(N=10, seed=0):\n",
        "        #np.random.seed(seed)\n",
        "        coords = np.random.rand(N+1, 2) * 100\n",
        "        D = np.zeros((N+1, N+1))\n",
        "        for i in range(N+1):\n",
        "            for j in range(N+1):\n",
        "                D[i,j] = np.linalg.norm(coords[i] - coords[j])\n",
        "        return D\n",
        "    \n",
        "    D = make_random_tsp(N=10, seed=1)\n",
        "\n",
        "    # Ground truth\n",
        "    solver = TSPBitmask(D)\n",
        "    gt_path, gt_cost = solver.run()\n",
        "    print(\"\\n=== Ground Truth (Held-Karp Exact) ===\")\n",
        "    print(\"Path :\", gt_path)\n",
        "    print(\"Cost :\", gt_cost)\n",
        "\n",
        "    # Run your solver\n",
        "    solver = TSP_PDF_SOVA_Viterbi_Final(D, damping=0.6, verbose=True)\n",
        "    my_path, my_cost = solver.solve(max_iter=10)\n",
        "\n",
        "    print(\"\\n=== PDF-SOVA-Viterbi Result ===\")\n",
        "    print(\"Path :\", my_path)\n",
        "    print(\"Cost :\", my_cost)\n",
        "\n",
        "    # =========================\n",
        "    # 5) 자동 검증\n",
        "    # =========================\n",
        "    print(\"\\n=== CHECK ===\")\n",
        "    print(\"Cost match?    \", abs(my_cost - gt_cost) < 1e-6)\n",
        "    print(\"Ordering match?\", my_path == gt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bqit2024",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
